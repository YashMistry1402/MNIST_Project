<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head></head><body>






















    
    
    
    

  <div class="border-box-sizing">
    <div class="container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1>SIT744 Assignment 1: Image Classification with Deep Feedforward Neural Network<a rel="noopener" class="anchor-link" href="#SIT744-Assignment-1:-Image-Classification-with-Deep-Feedforward-Neural-Network">&#182;</a></h1><div class="alert-info">
    <p>Due: <strong>8pm 24 August 2020</strong>  (Monday)</p>


This is an <strong>individual</strong> assignment. It contributes <strong>30%</strong> to your final mark. Read the assignment instruction carefully.

<h2> What to submit </h2>

<p>
This assignment is to be completed individually and submitted to CloudDeakin. <strong>By the due date, you are required to submit the following files to the corresponding Assignment (Dropbox) in CloudDeakin</strong>:

<ol>
<li>    <strong>[YourID]_assignment1_solution.ipynp</strong>:  This is your Python notebook solution source file. </li>
<li>    <strong>[YourID]_assingment1_output.html</strong>: This is the output of your Python notebook solution exported in HTML format.</li>
<li>    Extra files needed to complete your assignment, if any (e.g., images used in your answers).</li>
</ol>
</p>

<p>
For example, if your student ID is: 123456, you will then need to submit the following files:
<ul>
<li> 123456_assignment1_solution.ipynp </li>
<li> 123456_assignment1_output.html</li>
</ul>
</p>

<h2> Marking criteria </h2>

<p>
Your submission will be marked using the following criteria.

<ul>
<li> Showing good effort through completed tasks.</li>
<li> Applying deep learning theory to design suitable deep learning solutions for the tasks.</li>
<li> Critically evaluating and reflecting on the pros and cons of various design decisions.</li>
<li> Demonstrating creativity and resourcefulness in providing unique individual solutions.</li>
<li> Showing attention to details through a good quality assignment report.</li>
</ul>
</p>

<p>
Indicative weights of various tasks are provided, but the assignment will be marked by the overall quality per the above criteria.
</p>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Assignment objective<a rel="noopener" class="anchor-link" href="#Assignment-objective">&#182;</a></h2><p>This assignment is for you to demonstrate the knowledge in deep learning that you have acquired from the lectures and practical lab materials. Most tasks in this assignment are straightforward applications of the practical materials in weeks 1-5. Going through these materials before attempting this assignment is highly recommended.</p>
<p>In this assignment, you are going to work with the Fashion-MNIST dataset for image recognition. The dataset contains 10 classes of 28x28 grayscale images. You will see some examples in the visualization task below.</p>
<p>This assignment consists of five tasks.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[101]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install -q -U tensorflow&gt;<span class="o">=</span>1.8.0
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Task 1 Load the data<a rel="noopener" class="anchor-link" href="#Task-1-Load-the-data">&#182;</a></h2><p><em>(weight ~5%)</em></p>
<p>Load the Fashion MNIST dataset (<a rel="noopener" href="https://github.com/zalandoresearch/fashion-mnist">https://github.com/zalandoresearch/fashion-mnist</a>). You may get the data via Keras (keras.datasets) or Tensorflow Datasets (tfds).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[102]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Load the fashion-mnist pre-shuffled train data and test data</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Task 2 Understand the data<a rel="noopener" class="anchor-link" href="#Task-2-Understand-the-data">&#182;</a></h2><p><em>(weight ~15%)</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Display 100 images from the train set in the form of 10x10 matrix.</p>
<p>Answer the following questions:</p>
<ol>
<li>What are the unique labels in this dataset?</li>
<li>How many training images and how many test images?</li>
<li>What is the size of each image?</li>
<li>Find out the numeric range of the input. Do we need to rescale the input?</li>
<li>In our problem, what are the shapes of input tensors and target tensors? Do you need to reshape the input?</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[103]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Printing the number of training dataset and testing datasets</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_train shape:&quot;</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;y_train shape:&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>x_train shape: (60000, 28, 28)
y_train shape: (60000,)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ans 2. there are 60000 image sin train data and 10000 images in test data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>ANS 3. The size of each image is 28*28 as seen by the train.shape code</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ans 4. No we do not need to recale the input, but we still will be rescaling just in case</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[104]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Here we will define the text labels</span>
<span class="c1"># the index starts from 0 </span>
<span class="n">fashion_mnist_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;T-shirt/top&quot;</span><span class="p">,</span><span class="s2">&quot;Trouser&quot;</span><span class="p">,</span><span class="s2">&quot;Pullover&quot;</span><span class="p">,</span><span class="s2">&quot;Dress&quot;</span><span class="p">,</span><span class="s2">&quot;Coat&quot;</span><span class="p">,</span><span class="s2">&quot;Sandal&quot;</span><span class="p">,</span><span class="s2">&quot;Shirt&quot;</span><span class="p">,</span><span class="s2">&quot;Sneaker&quot;</span><span class="p">,</span><span class="s2">&quot;Bag&quot;</span><span class="p">,</span><span class="s2">&quot;Ankle boot&quot;</span><span class="p">]</span>   

<span class="c1"># Image index, you can pick any number</span>
<span class="n">img_ind</span> <span class="o">=</span> <span class="mi">5</span>



<span class="c1"># y_train will contains the lables</span>
<span class="c1"># It should be ranging from 0 to 9</span>
<span class="n">label_ind</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">img_ind</span><span class="p">]</span>



<span class="c1"># Printing the label</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;y = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">label_ind</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span><span class="p">(</span><span class="n">fashion_mnist_labels</span><span class="p">[</span><span class="n">label_ind</span><span class="p">]))</span>

 
<span class="c1"># Show one of the images from the training dataset #pullover</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="n">img_ind</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>y = 2 Pullover
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[104]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.image.AxesImage at 0x7fab765c1518&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Task 3 Construct an input pipeline<a rel="noopener" class="anchor-link" href="#Task-3-Construct-an-input-pipeline">&#182;</a></h2><p><em>(weight ~15%)</em></p>
<p>Creat train/validate/test data splits and construct tf.data pipelines. Make sure that the training data is batched.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[105]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#we rescale the model for smoothness </span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[106]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Here we break training data into training dataset and validation sets </span>
<span class="c1"># i decided to put 10000 data into validation set and keep remaining 50,000 for training set</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_valid</span><span class="p">)</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="mi">10000</span><span class="p">:],</span> <span class="n">x_train</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span> 
<span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="mi">10000</span><span class="p">:],</span> <span class="n">y_train</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[107]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Reshaping input data from (28, 28) to (28, 28, 1)</span>
<span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">x_valid</span> <span class="o">=</span> <span class="n">x_valid</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">y_valid</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[108]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Printing the training dataset shape</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_train shape:&quot;</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;y_train shape:&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>x_train shape: (50000, 28, 28, 1)
y_train shape: (50000, 10)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[109]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Print the number of training set </span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;train set&#39;</span><span class="p">)</span>
<span class="c1"># Print the number of validation</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;validation set&#39;</span><span class="p">)</span>
<span class="c1"># Print the number of test datasets</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;test set&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>50000 train set
10000 validation set
10000 test set
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Task 4 Construct a deep forward neural network<a rel="noopener" class="anchor-link" href="#Task-4-Construct-a-deep-forward-neural-network">&#182;</a></h2><p><em>(weight ~35%)</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 4.1 Setting up a model for training<a rel="noopener" class="anchor-link" href="#Task-4.1-Setting-up-a-model-for-training">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Construct a deep feedforward neural network. You need to decide and report the following configurations:</p>
<ul>
<li>Output layer: <ul>
<li>How many output nodes?</li>
<li>Which activation function?</li>
</ul>
</li>
<li>Hidden layers:<ul>
<li>How many hidden layers?</li>
<li>How many nodes in each layer?</li>
<li>Which activation function for each layer?</li>
</ul>
</li>
<li>Input layer<ul>
<li>What is the input size?</li>
</ul>
</li>
<li>The loss function</li>
<li>The metrics for model evaluation (which may be different from the loss function)</li>
<li>The optimiser</li>
</ul>
<p>Justify your model design decisions.</p>
<p>Plot the model structure <code>using keras.utils.plot_model</code> or similar tools.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>All the questions above can be anwered by the code and the explaination below with the help of the produced table and the structure generated by using keras.utils.plot_model</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[110]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="c1"># we will define the shape of the input in the first layer of the neural network</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span> 
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="c1"># taking a look at the summary of our model</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plot_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">to_file</span><span class="o">=</span><span class="s1">&#39;model.png&#39;</span><span class="p">,</span> <span class="n">show_shapes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">show_layer_names</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">rankdir</span><span class="o">=</span><span class="s1">&#39;TB&#39;</span><span class="p">,</span> <span class="n">expand_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">96</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &quot;sequential_8&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_14 (Conv2D)           (None, 28, 28, 64)        320       
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 14, 14, 64)        0         
_________________________________________________________________
dropout_21 (Dropout)         (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 14, 14, 32)        8224      
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 7, 7, 32)          0         
_________________________________________________________________
dropout_22 (Dropout)         (None, 7, 7, 32)          0         
_________________________________________________________________
flatten_7 (Flatten)          (None, 1568)              0         
_________________________________________________________________
dense_16 (Dense)             (None, 256)               401664    
_________________________________________________________________
dropout_23 (Dropout)         (None, 256)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 10)                2570      
=================================================================
Total params: 412,778
Trainable params: 412,778
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[110]:</div>




<div class="output_png output_subarea output_execute_result">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Compiling the model</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[111]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
             <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 4.2 Fitting the model<a rel="noopener" class="anchor-link" href="#Task-4.2-Fitting-the-model">&#182;</a></h3><p>Now fit the model. Decide and report the following training setting:</p>
<ol>
<li>The training batch size</li>
<li>The number of training epochs (at least 1,000 epochs recommended)</li>
<li>The learning rate. If you used momentum or a learning rate schedule, please report the configuration as well.</li>
</ol>
<p>Plot the training and validation loss and accuracy. Answer the following questions:</p>
<ol>
<li>Do you see overfitting or underfitting? Why?</li>
<li>If you see overfitting, at which epoch did it happen?</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong> The batch size and the number of epoch is visible in the below code.</strong>
<strong>i have noticed overfitting at epoch 13</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[112]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="k">import</span> <span class="n">ModelCheckpoint</span>

<span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">&#39;model.weights.best.hdf5&#39;</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span>
         <span class="n">y_train</span><span class="p">,</span>
         <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
         <span class="n">epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
<span class="c1"># the number of epoch is reduced due to low gpu power computer, with high end power machine the number can be increased.</span>
<span class="c1"># i choose 25 epoch runs for my best accuracy and performace of my machine (it took 3 min for 25 epoch runs)</span>
         <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
         <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/25
770/782 [============================&gt;.] - ETA: 0s - loss: 0.6346 - accuracy: 0.7640
Epoch 00001: val_loss improved from inf to 0.40966, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.6322 - accuracy: 0.7650 - val_loss: 0.4097 - val_accuracy: 0.8508
Epoch 2/25
777/782 [============================&gt;.] - ETA: 0s - loss: 0.4257 - accuracy: 0.8430
Epoch 00002: val_loss improved from 0.40966 to 0.35343, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.4259 - accuracy: 0.8429 - val_loss: 0.3534 - val_accuracy: 0.8717
Epoch 3/25
774/782 [============================&gt;.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8577
Epoch 00003: val_loss improved from 0.35343 to 0.31268, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.3873 - accuracy: 0.8578 - val_loss: 0.3127 - val_accuracy: 0.8833
Epoch 4/25
772/782 [============================&gt;.] - ETA: 0s - loss: 0.3605 - accuracy: 0.8684
Epoch 00004: val_loss improved from 0.31268 to 0.29216, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.3606 - accuracy: 0.8686 - val_loss: 0.2922 - val_accuracy: 0.8925
Epoch 5/25
779/782 [============================&gt;.] - ETA: 0s - loss: 0.3420 - accuracy: 0.8749
Epoch 00005: val_loss improved from 0.29216 to 0.28546, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.3419 - accuracy: 0.8749 - val_loss: 0.2855 - val_accuracy: 0.8939
Epoch 6/25
770/782 [============================&gt;.] - ETA: 0s - loss: 0.3236 - accuracy: 0.8812
Epoch 00006: val_loss improved from 0.28546 to 0.26190, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.3231 - accuracy: 0.8814 - val_loss: 0.2619 - val_accuracy: 0.9029
Epoch 7/25
772/782 [============================&gt;.] - ETA: 0s - loss: 0.3133 - accuracy: 0.8861
Epoch 00007: val_loss improved from 0.26190 to 0.26146, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.3135 - accuracy: 0.8860 - val_loss: 0.2615 - val_accuracy: 0.9059
Epoch 8/25
777/782 [============================&gt;.] - ETA: 0s - loss: 0.3014 - accuracy: 0.8890
Epoch 00008: val_loss improved from 0.26146 to 0.25181, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.3012 - accuracy: 0.8890 - val_loss: 0.2518 - val_accuracy: 0.9077
Epoch 9/25
774/782 [============================&gt;.] - ETA: 0s - loss: 0.2936 - accuracy: 0.8910
Epoch 00009: val_loss improved from 0.25181 to 0.24571, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.2940 - accuracy: 0.8909 - val_loss: 0.2457 - val_accuracy: 0.9076
Epoch 10/25
780/782 [============================&gt;.] - ETA: 0s - loss: 0.2818 - accuracy: 0.8965
Epoch 00010: val_loss improved from 0.24571 to 0.23657, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.2817 - accuracy: 0.8965 - val_loss: 0.2366 - val_accuracy: 0.9109
Epoch 11/25
771/782 [============================&gt;.] - ETA: 0s - loss: 0.2736 - accuracy: 0.8995
Epoch 00011: val_loss did not improve from 0.23657
782/782 [==============================] - 4s 5ms/step - loss: 0.2737 - accuracy: 0.8996 - val_loss: 0.2399 - val_accuracy: 0.9091
Epoch 12/25
779/782 [============================&gt;.] - ETA: 0s - loss: 0.2681 - accuracy: 0.9003
Epoch 00012: val_loss improved from 0.23657 to 0.22646, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.2684 - accuracy: 0.9002 - val_loss: 0.2265 - val_accuracy: 0.9154
Epoch 13/25
772/782 [============================&gt;.] - ETA: 0s - loss: 0.2621 - accuracy: 0.9019
Epoch 00013: val_loss did not improve from 0.22646
782/782 [==============================] - 4s 5ms/step - loss: 0.2618 - accuracy: 0.9021 - val_loss: 0.2308 - val_accuracy: 0.9134
Epoch 14/25
779/782 [============================&gt;.] - ETA: 0s - loss: 0.2543 - accuracy: 0.9043
Epoch 00014: val_loss improved from 0.22646 to 0.22142, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.2541 - accuracy: 0.9044 - val_loss: 0.2214 - val_accuracy: 0.9176
Epoch 15/25
778/782 [============================&gt;.] - ETA: 0s - loss: 0.2498 - accuracy: 0.9085
Epoch 00015: val_loss did not improve from 0.22142
782/782 [==============================] - 3s 4ms/step - loss: 0.2498 - accuracy: 0.9086 - val_loss: 0.2496 - val_accuracy: 0.9042
Epoch 16/25
771/782 [============================&gt;.] - ETA: 0s - loss: 0.2461 - accuracy: 0.9093
Epoch 00016: val_loss improved from 0.22142 to 0.21578, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.2453 - accuracy: 0.9096 - val_loss: 0.2158 - val_accuracy: 0.9204
Epoch 17/25
771/782 [============================&gt;.] - ETA: 0s - loss: 0.2389 - accuracy: 0.9101
Epoch 00017: val_loss improved from 0.21578 to 0.21012, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 4ms/step - loss: 0.2395 - accuracy: 0.9101 - val_loss: 0.2101 - val_accuracy: 0.9217
Epoch 18/25
774/782 [============================&gt;.] - ETA: 0s - loss: 0.2375 - accuracy: 0.9113
Epoch 00018: val_loss did not improve from 0.21012
782/782 [==============================] - 4s 4ms/step - loss: 0.2372 - accuracy: 0.9114 - val_loss: 0.2185 - val_accuracy: 0.9170
Epoch 19/25
781/782 [============================&gt;.] - ETA: 0s - loss: 0.2363 - accuracy: 0.9128
Epoch 00019: val_loss did not improve from 0.21012
782/782 [==============================] - 4s 4ms/step - loss: 0.2363 - accuracy: 0.9128 - val_loss: 0.2130 - val_accuracy: 0.9215
Epoch 20/25
776/782 [============================&gt;.] - ETA: 0s - loss: 0.2331 - accuracy: 0.9136
Epoch 00020: val_loss improved from 0.21012 to 0.20963, saving model to model.weights.best.hdf5
782/782 [==============================] - 3s 4ms/step - loss: 0.2335 - accuracy: 0.9134 - val_loss: 0.2096 - val_accuracy: 0.9211
Epoch 21/25
770/782 [============================&gt;.] - ETA: 0s - loss: 0.2256 - accuracy: 0.9156
Epoch 00021: val_loss did not improve from 0.20963
782/782 [==============================] - 3s 4ms/step - loss: 0.2267 - accuracy: 0.9154 - val_loss: 0.2394 - val_accuracy: 0.9077
Epoch 22/25
780/782 [============================&gt;.] - ETA: 0s - loss: 0.2259 - accuracy: 0.9159
Epoch 00022: val_loss improved from 0.20963 to 0.20406, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.2257 - accuracy: 0.9160 - val_loss: 0.2041 - val_accuracy: 0.9247
Epoch 23/25
775/782 [============================&gt;.] - ETA: 0s - loss: 0.2231 - accuracy: 0.9163
Epoch 00023: val_loss improved from 0.20406 to 0.20392, saving model to model.weights.best.hdf5
782/782 [==============================] - 3s 4ms/step - loss: 0.2229 - accuracy: 0.9163 - val_loss: 0.2039 - val_accuracy: 0.9224
Epoch 24/25
775/782 [============================&gt;.] - ETA: 0s - loss: 0.2209 - accuracy: 0.9173
Epoch 00024: val_loss did not improve from 0.20392
782/782 [==============================] - 3s 4ms/step - loss: 0.2212 - accuracy: 0.9171 - val_loss: 0.2091 - val_accuracy: 0.9230
Epoch 25/25
771/782 [============================&gt;.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9170
Epoch 00025: val_loss did not improve from 0.20392
782/782 [==============================] - 3s 4ms/step - loss: 0.2214 - accuracy: 0.9170 - val_loss: 0.2095 - val_accuracy: 0.9224
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[112]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;tensorflow.python.keras.callbacks.History at 0x7fab7652ef98&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[113]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;model.weights.best.hdf5&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[114]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Printing the test accuracy</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;Test accuracy:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
 Test accuracy: 0.9200000166893005
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 4.3 Check the convergence through gradient<a rel="noopener" class="anchor-link" href="#Task-4.3-Check-the-convergence-through-gradient">&#182;</a></h3><p>Use  TensorBoard to check the gradients.</p>
<ul>
<li>Do you see vanishing or exploding gradients?</li>
<li>Use the gradient norm to check if the training has converged to a local minimum.</li>
</ul>
<p>Show screenshots of your TensorBoard output.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Task 5 Fine-tuning the model<a rel="noopener" class="anchor-link" href="#Task-5-Fine-tuning-the-model">&#182;</a></h2><p><em>(weight ~30%)</em></p>
<p>You may see above that your model is overfitting. There are multiple things you can do. Below are some options:</p>
<ol>
<li>Add dropout</li>
<li>Add Batch Normalisation</li>
<li>Add layer-specific weight regularizations</li>
<li>Change the learning rate</li>
</ol>
<p>Apply different regularisation techniques to the model training. You may also try other techniques for improving training such as learning rate scheduling (see <a rel="noopener" href="https://www.tensorflow.org/guide/keras/train_and_evaluate#using_learning_rate_schedules">https://www.tensorflow.org/guide/keras/train_and_evaluate#using_learning_rate_schedules</a>).</p>
<p>Run <strong>five or more</strong> experiments of different training configurations and record the test accuracy achieved in the Markdown table below. You may modify the table heading to match your experiment design.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<table>
<thead><tr>
<th>Dropout (rate)</th>
<th>Batch Normalisation (Y/N)</th>
<th>Optimiser</th>
<th>Learning Rate</th>
<th>Number of Epochs</th>
<th>Test Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Answer the following questions:</p>
<ol>
<li>Which configuration achieved the best test accuracy?</li>
<li>Which setting had the most impact and which one had the least impact?</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Task 6 Generate HTML output<a rel="noopener" class="anchor-link" href="#Task-6-Generate-HTML-output">&#182;</a></h2><p>Use <em>nbconvert</em> to convert your completed notebook into an HTML file and name it <strong>[YourID]_assingment1_output.html</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[115]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">nbconvert</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (5.6.1)
Requirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.8.4)
Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.6.3)
Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert) (3.1.5)
Requirement already satisfied: jinja2&gt;=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.11.2)
Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.4.4)
Requirement already satisfied: traitlets&gt;=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.3.3)
Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.1.3)
Requirement already satisfied: nbformat&gt;=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (5.0.7)
Requirement already satisfied: pandocfilters&gt;=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (1.4.2)
Requirement already satisfied: entrypoints&gt;=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.3)
Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.6.0)
Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bleach-&gt;nbconvert) (1.15.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach-&gt;nbconvert) (20.4)
Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach-&gt;nbconvert) (0.5.1)
Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2&gt;=2.4-&gt;nbconvert) (1.1.1)
Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets&gt;=4.2-&gt;nbconvert) (4.4.2)
Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets&gt;=4.2-&gt;nbconvert) (0.2.0)
Requirement already satisfied: jsonschema!=2.5.0,&gt;=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat&gt;=4.4-&gt;nbconvert) (2.6.0)
Requirement already satisfied: pyparsing&gt;=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging-&gt;bleach-&gt;nbconvert) (2.4.7)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[116]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>jupyter nbconvert --to html 218612723_Assignment1_solution.ipynb
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[NbConvertApp] WARNING | pattern u&#39;218612723_Assignment1_solution.ipynb&#39; matched no files
This application is used to convert notebook files (*.ipynb) to various other
formats.

WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.

Options
-------

Arguments that take values are actually convenience aliases to full
Configurables, whose aliases are listed on the help line. For more information
on full configurables, see &#39;--help-all&#39;.

--execute
    Execute the notebook prior to export.
--allow-errors
    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if &#39;--execute&#39; was specified, too.
--no-input
    Exclude input cells and output prompts from converted document. 
    This mode is ideal for generating code-free reports.
--stdout
    Write notebook output to stdout instead of files.
--stdin
    read a single notebook file from stdin. Write the resulting notebook with default basename &#39;notebook.*&#39;
--inplace
    Run nbconvert in place, overwriting the existing notebook (only 
    relevant when converting to notebook format)
-y
    Answer yes to any questions instead of prompting.
--clear-output
    Clear output of current file and save in place, 
    overwriting the existing notebook.
--debug
    set log level to logging.DEBUG (maximize logging output)
--no-prompt
    Exclude input and output prompts from converted document.
--generate-config
    generate default config file
--nbformat=&lt;Enum&gt; (NotebookExporter.nbformat_version)
    Default: 4
    Choices: [1, 2, 3, 4]
    The nbformat version to write. Use this to downgrade notebooks.
--output-dir=&lt;Unicode&gt; (FilesWriter.build_directory)
    Default: &#39;&#39;
    Directory to write output(s) to. Defaults to output to the directory of each
    notebook. To recover previous default behaviour (outputting to the current
    working directory) use . as the flag value.
--writer=&lt;DottedObjectName&gt; (NbConvertApp.writer_class)
    Default: &#39;FilesWriter&#39;
    Writer class used to write the  results of the conversion
--log-level=&lt;Enum&gt; (Application.log_level)
    Default: 30
    Choices: (0, 10, 20, 30, 40, 50, &#39;DEBUG&#39;, &#39;INFO&#39;, &#39;WARN&#39;, &#39;ERROR&#39;, &#39;CRITICAL&#39;)
    Set the log level by value or name.
--reveal-prefix=&lt;Unicode&gt; (SlidesExporter.reveal_url_prefix)
    Default: u&#39;&#39;
    The URL prefix for reveal.js (version 3.x). This defaults to the reveal CDN,
    but can be any url pointing to a copy  of reveal.js.
    For speaker notes to work, this must be a relative path to a local  copy of
    reveal.js: e.g., &quot;reveal.js&quot;.
    If a relative path is given, it must be a subdirectory of the current
    directory (from which the server is run).
    See the usage documentation
    (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-
    slideshow) for more details.
--to=&lt;Unicode&gt; (NbConvertApp.export_format)
    Default: &#39;html&#39;
    The export format to be used, either one of the built-in formats
    [&#39;asciidoc&#39;, &#39;custom&#39;, &#39;html&#39;, &#39;latex&#39;, &#39;markdown&#39;, &#39;notebook&#39;, &#39;pdf&#39;,
    &#39;python&#39;, &#39;rst&#39;, &#39;script&#39;, &#39;slides&#39;] or a dotted object name that represents
    the import path for an `Exporter` class
--template=&lt;Unicode&gt; (TemplateExporter.template_file)
    Default: u&#39;&#39;
    Name of the template file to use
--output=&lt;Unicode&gt; (NbConvertApp.output_base)
    Default: &#39;&#39;
    overwrite base name use for output files. can only be used when converting
    one notebook at a time.
--post=&lt;DottedOrNone&gt; (NbConvertApp.postprocessor_class)
    Default: u&#39;&#39;
    PostProcessor class used to write the results of the conversion
--config=&lt;Unicode&gt; (JupyterApp.config_file)
    Default: u&#39;&#39;
    Full path of a config file.

To see all available configurables, use `--help-all`

Examples
--------

    The simplest way to use nbconvert is
    
    &gt; jupyter nbconvert mynotebook.ipynb
    
    which will convert mynotebook.ipynb to the default format (probably HTML).
    
    You can specify the export format with `--to`.
    Options include [&#39;asciidoc&#39;, &#39;custom&#39;, &#39;html&#39;, &#39;latex&#39;, &#39;markdown&#39;, &#39;notebook&#39;, &#39;pdf&#39;, &#39;python&#39;, &#39;rst&#39;, &#39;script&#39;, &#39;slides&#39;].
    
    &gt; jupyter nbconvert --to latex mynotebook.ipynb
    
    Both HTML and LaTeX support multiple output templates. LaTeX includes
    &#39;base&#39;, &#39;article&#39; and &#39;report&#39;.  HTML includes &#39;basic&#39; and &#39;full&#39;. You
    can specify the flavor of the format used.
    
    &gt; jupyter nbconvert --to html --template basic mynotebook.ipynb
    
    You can also pipe the output to stdout, rather than a file
    
    &gt; jupyter nbconvert mynotebook.ipynb --stdout
    
    PDF is generated via latex
    
    &gt; jupyter nbconvert mynotebook.ipynb --to pdf
    
    You can get (and serve) a Reveal.js-powered slideshow
    
    &gt; jupyter nbconvert myslides.ipynb --to slides --post serve
    
    Multiple notebooks can be given at the command line in a couple of 
    different ways:
    
    &gt; jupyter nbconvert notebook*.ipynb
    &gt; jupyter nbconvert notebook1.ipynb notebook2.ipynb
    
    or you can specify the notebooks list in a config file, containing::
    
        c.NbConvertApp.notebooks = [&quot;my_notebook.ipynb&quot;]
    
    &gt; jupyter nbconvert --config mycfg.py

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong>END OF ASSIGNMENT ONE</strong></p>

</div>
</div>
</div>
    </div>
  </div>


 



<script type="text/javascript" src="/d2l/common/math/MathML.js?v=20.21.8.31625 "></script><script type="text/javascript">document.addEventListener('DOMContentLoaded', function() { D2LMathML.DesktopInit('https://s.brightspace.com/lib/mathjax/2.7.4/MathJax.js?config=MML_HTMLorMML','https://s.brightspace.com/lib/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML','130',true); });</script></body></html>