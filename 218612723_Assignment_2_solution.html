<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head></head><body>






















    
    
    
    

  <div class="border-box-sizing">
    <div class="container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1>SIT744 Assignment 2: Efficient Training of Convolutional Neural Network<a rel="noopener" class="anchor-link" href="#SIT744-Assignment-2:-Efficient-Training-of-Convolutional-Neural-Network">&#182;</a></h1><div class="alert-info">
    <p>Due: <strong>11:59pm 21 September 2020</strong>  (Monday)</p>

This is an <strong>individual</strong> assignment. It contributes <strong>45%</strong> to your final mark. Read the assignment instruction carefully.

<h2> What to submit </h2>

<p>
This assignment is to be completed individually and submitted to CloudDeakin. <strong>By the due date, you are required to submit the following files to the corresponding Assignment (Dropbox) in CloudDeakin</strong>:

<ol>
<li>    <strong>[YourID]_assignment2_solution.ipynp</strong>:  This is your Python notebook solution source file. </li>
<li>    <strong>[YourID]_assingment2_output.html</strong>: This is the output of your Python notebook solution exported in HTML format.</li>
<li>    Extra files needed to complete your assignment, if any (e.g., images used in your answers).</li>
</ol>
</p>

<p>
For example, if your student ID is: 123456, you will then need to submit the following files:
<ul>
<li> 123456_assignment2_solution.ipynp </li>
<li> 123456_assignment2_output.html</li>
</ul>
</p>

<h2> Warning </h2>

Some components of this assignment may involve heavy computation that runs for a long duration. Please start early to avoid missing the assignment due date.

<h2> Marking criteria </h2>

<p>
Your submission will be marked using the following criteria.

<ul>
<li> Showing good effort through completed tasks.</li>
<li> Applying deep learning theory to design suitable deep learning solutions for the tasks.</li>
<li> Critically evaluating and reflecting on the pros and cons of various design decisions.</li>
<li> Demonstrating creativity and resourcefulness in providing unique individual solutions.</li>
<li> Showing attention to details through a good quality assignment report.</li>
</ul>
</p>

<p>
Indicative weights of various tasks are provided, but the assignment will be marked by the overall quality per the above criteria.
</p>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Assignment objective<a rel="noopener" class="anchor-link" href="#Assignment-objective">&#182;</a></h2><p>This assignment is to feedback on your learning in deep learning theory and its application to  data analytics or artificial intelligence problems.</p>
<p>It builds on Assignment 1 but requires a higher level of mastery of deep learning theory and programming/engineering skills. In particular, you will experience training a much deeper network on a large-scale dataset. You will encounter  practical issues that help you consolidate textbook learning.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Task 1 Solving Fashion-MNIST with Convolutional Neural Networks<a rel="noopener" class="anchor-link" href="#Task-1-Solving-Fashion-MNIST-with-Convolutional-Neural-Networks">&#182;</a></h2><p><em>(weight ~18%)</em></p>
<p>In Assignment 1, you tackled the image classification problem in Fashion-MNIST. There, you used a Densely Connected Neural Network. You should now know that is not an optimal model architecture for the problem. In Assignment 2, you will apply the best practices of deep-learning computer vision to improve the image classification performance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 1.1 Revisit Fashion-MNIST classification with DNN<a rel="noopener" class="anchor-link" href="#Task-1.1-Revisit-Fashion-MNIST-classification-with-DNN">&#182;</a></h3><p><em>(weight ~2%)</em></p>
<p>Review your Assignment 1 solution, and reproduce the experiment here. Try to improve the model without changing the model architecture.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install tensorflow

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Load the fashion-mnist pre-shuffled train data and test data</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)
Requirement already satisfied: keras-preprocessing&lt;1.2,&gt;=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)
Requirement already satisfied: tensorflow-estimator&lt;2.4.0,&gt;=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)
Requirement already satisfied: termcolor&gt;=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)
Requirement already satisfied: grpcio&gt;=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.32.0)
Requirement already satisfied: protobuf&gt;=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)
Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)
Requirement already satisfied: google-pasta&gt;=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)
Requirement already satisfied: absl-py&gt;=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)
Requirement already satisfied: wrapt&gt;=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)
Requirement already satisfied: six&gt;=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)
Requirement already satisfied: numpy&lt;1.19.0,&gt;=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)
Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)
Requirement already satisfied: tensorboard&lt;3,&gt;=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)
Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)
Requirement already satisfied: wheel&gt;=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)
Requirement already satisfied: h5py&lt;2.11.0,&gt;=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf&gt;=3.9.2-&gt;tensorflow) (50.3.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (3.2.2)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (1.0.1)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (1.7.0)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (0.4.1)
Requirement already satisfied: requests&lt;3,&gt;=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (2.23.0)
Requirement already satisfied: google-auth&lt;2,&gt;=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (1.17.2)
Requirement already satisfied: importlib-metadata; python_version &lt; &quot;3.8&quot; in /usr/local/lib/python3.6/dist-packages (from markdown&gt;=2.6.8-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (2.0.0)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (1.3.0)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (1.24.3)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (2.10)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (3.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (2020.6.20)
Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (4.1.1)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (0.2.8)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4; python_version &gt;= &quot;3&quot; in /usr/local/lib/python3.6/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (4.6)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version &lt; &quot;3.8&quot;-&gt;markdown&gt;=2.6.8-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (3.2.0)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (3.1.0)
Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow) (0.4.8)
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
32768/29515 [=================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26427392/26421880 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
8192/5148 [===============================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4423680/4422102 [==============================] - 0s 0us/step
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="k">import</span> <span class="n">ModelCheckpoint</span>

<span class="c1">#we rescale the model for smoothness </span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="mi">255</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="mi">255</span>

<span class="c1">#Breaking training data into training(50000) and validation(10000) sets</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_valid</span><span class="p">)</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="mi">10000</span><span class="p">:],</span> <span class="n">x_train</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span>
<span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="mi">10000</span><span class="p">:],</span> <span class="n">y_train</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span>

<span class="c1"># Reshaping input data from (28, 28) to (28, 28, 1)</span>
<span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">x_valid</span> <span class="o">=</span> <span class="n">x_valid</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">y_valid</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="c1"># we will define the shape of the input in the first layer of the neural network</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span> 
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="c1"># taking a look at the summary of our model</span>

<span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plot_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">to_file</span><span class="o">=</span><span class="s1">&#39;model.png&#39;</span><span class="p">,</span> <span class="n">show_shapes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">show_layer_names</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">rankdir</span><span class="o">=</span><span class="s1">&#39;TB&#39;</span><span class="p">,</span> <span class="n">expand_nested</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">96</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
             <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">&#39;model.weights.best.hdf5&#39;</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span>
         <span class="n">y_train</span><span class="p">,</span>
         <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
         <span class="n">epochs</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span>
         <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
         <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/75
782/782 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.7689
Epoch 00001: val_loss improved from inf to 0.41385, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.6250 - accuracy: 0.7689 - val_loss: 0.4138 - val_accuracy: 0.8456
Epoch 2/75
775/782 [============================&gt;.] - ETA: 0s - loss: 0.4331 - accuracy: 0.8417
Epoch 00002: val_loss improved from 0.41385 to 0.34885, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.4333 - accuracy: 0.8415 - val_loss: 0.3489 - val_accuracy: 0.8757
Epoch 3/75
776/782 [============================&gt;.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8593
Epoch 00003: val_loss improved from 0.34885 to 0.31546, saving model to model.weights.best.hdf5
782/782 [==============================] - 3s 4ms/step - loss: 0.3845 - accuracy: 0.8595 - val_loss: 0.3155 - val_accuracy: 0.8849
Epoch 4/75
776/782 [============================&gt;.] - ETA: 0s - loss: 0.3604 - accuracy: 0.8672
Epoch 00004: val_loss improved from 0.31546 to 0.29413, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.3599 - accuracy: 0.8674 - val_loss: 0.2941 - val_accuracy: 0.8907
Epoch 5/75
772/782 [============================&gt;.] - ETA: 0s - loss: 0.3403 - accuracy: 0.8748
Epoch 00005: val_loss improved from 0.29413 to 0.27786, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.3404 - accuracy: 0.8747 - val_loss: 0.2779 - val_accuracy: 0.8970
Epoch 6/75
776/782 [============================&gt;.] - ETA: 0s - loss: 0.3240 - accuracy: 0.8810
Epoch 00006: val_loss improved from 0.27786 to 0.26458, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 4ms/step - loss: 0.3242 - accuracy: 0.8809 - val_loss: 0.2646 - val_accuracy: 0.9013
Epoch 7/75
778/782 [============================&gt;.] - ETA: 0s - loss: 0.3126 - accuracy: 0.8853
Epoch 00007: val_loss improved from 0.26458 to 0.25713, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 4ms/step - loss: 0.3124 - accuracy: 0.8853 - val_loss: 0.2571 - val_accuracy: 0.9059
Epoch 8/75
780/782 [============================&gt;.] - ETA: 0s - loss: 0.3008 - accuracy: 0.8882
Epoch 00008: val_loss did not improve from 0.25713
782/782 [==============================] - 3s 4ms/step - loss: 0.3007 - accuracy: 0.8882 - val_loss: 0.2582 - val_accuracy: 0.9032
Epoch 9/75
774/782 [============================&gt;.] - ETA: 0s - loss: 0.2915 - accuracy: 0.8920
Epoch 00009: val_loss improved from 0.25713 to 0.23940, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.2912 - accuracy: 0.8922 - val_loss: 0.2394 - val_accuracy: 0.9098
Epoch 10/75
776/782 [============================&gt;.] - ETA: 0s - loss: 0.2806 - accuracy: 0.8962
Epoch 00010: val_loss improved from 0.23940 to 0.23714, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.2803 - accuracy: 0.8963 - val_loss: 0.2371 - val_accuracy: 0.9122
Epoch 11/75
781/782 [============================&gt;.] - ETA: 0s - loss: 0.2759 - accuracy: 0.8971
Epoch 00011: val_loss improved from 0.23714 to 0.23126, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 4ms/step - loss: 0.2759 - accuracy: 0.8971 - val_loss: 0.2313 - val_accuracy: 0.9122
Epoch 12/75
779/782 [============================&gt;.] - ETA: 0s - loss: 0.2686 - accuracy: 0.9017
Epoch 00012: val_loss did not improve from 0.23126
782/782 [==============================] - 3s 4ms/step - loss: 0.2686 - accuracy: 0.9017 - val_loss: 0.2334 - val_accuracy: 0.9098
Epoch 13/75
769/782 [============================&gt;.] - ETA: 0s - loss: 0.2648 - accuracy: 0.9020
Epoch 00013: val_loss improved from 0.23126 to 0.22928, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 4ms/step - loss: 0.2648 - accuracy: 0.9019 - val_loss: 0.2293 - val_accuracy: 0.9155
Epoch 14/75
773/782 [============================&gt;.] - ETA: 0s - loss: 0.2573 - accuracy: 0.9044
Epoch 00014: val_loss improved from 0.22928 to 0.22628, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.2572 - accuracy: 0.9043 - val_loss: 0.2263 - val_accuracy: 0.9142
Epoch 15/75
779/782 [============================&gt;.] - ETA: 0s - loss: 0.2513 - accuracy: 0.9071
Epoch 00015: val_loss improved from 0.22628 to 0.21799, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.2510 - accuracy: 0.9073 - val_loss: 0.2180 - val_accuracy: 0.9174
Epoch 16/75
779/782 [============================&gt;.] - ETA: 0s - loss: 0.2482 - accuracy: 0.9094
Epoch 00016: val_loss did not improve from 0.21799
782/782 [==============================] - 3s 4ms/step - loss: 0.2483 - accuracy: 0.9094 - val_loss: 0.2181 - val_accuracy: 0.9218
Epoch 17/75
779/782 [============================&gt;.] - ETA: 0s - loss: 0.2448 - accuracy: 0.9095
Epoch 00017: val_loss improved from 0.21799 to 0.21002, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.2448 - accuracy: 0.9095 - val_loss: 0.2100 - val_accuracy: 0.9212
Epoch 18/75
782/782 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.9115
Epoch 00018: val_loss did not improve from 0.21002
782/782 [==============================] - 3s 4ms/step - loss: 0.2380 - accuracy: 0.9115 - val_loss: 0.2236 - val_accuracy: 0.9158
Epoch 19/75
778/782 [============================&gt;.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9140
Epoch 00019: val_loss did not improve from 0.21002
782/782 [==============================] - 3s 4ms/step - loss: 0.2306 - accuracy: 0.9140 - val_loss: 0.2195 - val_accuracy: 0.9169
Epoch 20/75
771/782 [============================&gt;.] - ETA: 0s - loss: 0.2329 - accuracy: 0.9142
Epoch 00020: val_loss improved from 0.21002 to 0.20756, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.2333 - accuracy: 0.9140 - val_loss: 0.2076 - val_accuracy: 0.9220
Epoch 21/75
772/782 [============================&gt;.] - ETA: 0s - loss: 0.2253 - accuracy: 0.9148
Epoch 00021: val_loss improved from 0.20756 to 0.20722, saving model to model.weights.best.hdf5
782/782 [==============================] - 3s 4ms/step - loss: 0.2248 - accuracy: 0.9150 - val_loss: 0.2072 - val_accuracy: 0.9224
Epoch 22/75
774/782 [============================&gt;.] - ETA: 0s - loss: 0.2251 - accuracy: 0.9153
Epoch 00022: val_loss did not improve from 0.20722
782/782 [==============================] - 3s 4ms/step - loss: 0.2248 - accuracy: 0.9153 - val_loss: 0.2200 - val_accuracy: 0.9160
Epoch 23/75
778/782 [============================&gt;.] - ETA: 0s - loss: 0.2208 - accuracy: 0.9166
Epoch 00023: val_loss did not improve from 0.20722
782/782 [==============================] - 3s 4ms/step - loss: 0.2206 - accuracy: 0.9166 - val_loss: 0.2073 - val_accuracy: 0.9233
Epoch 24/75
781/782 [============================&gt;.] - ETA: 0s - loss: 0.2192 - accuracy: 0.9182
Epoch 00024: val_loss did not improve from 0.20722
782/782 [==============================] - 3s 4ms/step - loss: 0.2191 - accuracy: 0.9183 - val_loss: 0.2121 - val_accuracy: 0.9193
Epoch 25/75
778/782 [============================&gt;.] - ETA: 0s - loss: 0.2188 - accuracy: 0.9188
Epoch 00025: val_loss improved from 0.20722 to 0.20464, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 4ms/step - loss: 0.2189 - accuracy: 0.9187 - val_loss: 0.2046 - val_accuracy: 0.9253
Epoch 26/75
772/782 [============================&gt;.] - ETA: 0s - loss: 0.2104 - accuracy: 0.9219
Epoch 00026: val_loss did not improve from 0.20464
782/782 [==============================] - 4s 4ms/step - loss: 0.2106 - accuracy: 0.9218 - val_loss: 0.2082 - val_accuracy: 0.9224
Epoch 27/75
780/782 [============================&gt;.] - ETA: 0s - loss: 0.2108 - accuracy: 0.9210
Epoch 00027: val_loss did not improve from 0.20464
782/782 [==============================] - 3s 4ms/step - loss: 0.2108 - accuracy: 0.9209 - val_loss: 0.2064 - val_accuracy: 0.9232
Epoch 28/75
775/782 [============================&gt;.] - ETA: 0s - loss: 0.2085 - accuracy: 0.9223
Epoch 00028: val_loss improved from 0.20464 to 0.20004, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 4ms/step - loss: 0.2084 - accuracy: 0.9224 - val_loss: 0.2000 - val_accuracy: 0.9247
Epoch 29/75
771/782 [============================&gt;.] - ETA: 0s - loss: 0.2043 - accuracy: 0.9227
Epoch 00029: val_loss did not improve from 0.20004
782/782 [==============================] - 3s 4ms/step - loss: 0.2041 - accuracy: 0.9228 - val_loss: 0.2108 - val_accuracy: 0.9223
Epoch 30/75
775/782 [============================&gt;.] - ETA: 0s - loss: 0.2044 - accuracy: 0.9227
Epoch 00030: val_loss did not improve from 0.20004
782/782 [==============================] - 3s 4ms/step - loss: 0.2042 - accuracy: 0.9228 - val_loss: 0.2023 - val_accuracy: 0.9235
Epoch 31/75
777/782 [============================&gt;.] - ETA: 0s - loss: 0.2016 - accuracy: 0.9239
Epoch 00031: val_loss did not improve from 0.20004
782/782 [==============================] - 3s 4ms/step - loss: 0.2015 - accuracy: 0.9240 - val_loss: 0.2054 - val_accuracy: 0.9222
Epoch 32/75
776/782 [============================&gt;.] - ETA: 0s - loss: 0.2000 - accuracy: 0.9256
Epoch 00032: val_loss did not improve from 0.20004
782/782 [==============================] - 3s 4ms/step - loss: 0.2000 - accuracy: 0.9257 - val_loss: 0.2052 - val_accuracy: 0.9233
Epoch 33/75
775/782 [============================&gt;.] - ETA: 0s - loss: 0.1980 - accuracy: 0.9246
Epoch 00033: val_loss did not improve from 0.20004
782/782 [==============================] - 3s 4ms/step - loss: 0.1981 - accuracy: 0.9246 - val_loss: 0.2167 - val_accuracy: 0.9194
Epoch 34/75
775/782 [============================&gt;.] - ETA: 0s - loss: 0.1992 - accuracy: 0.9257
Epoch 00034: val_loss improved from 0.20004 to 0.19978, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.1990 - accuracy: 0.9258 - val_loss: 0.1998 - val_accuracy: 0.9264
Epoch 35/75
777/782 [============================&gt;.] - ETA: 0s - loss: 0.1966 - accuracy: 0.9261
Epoch 00035: val_loss did not improve from 0.19978
782/782 [==============================] - 3s 4ms/step - loss: 0.1964 - accuracy: 0.9261 - val_loss: 0.2018 - val_accuracy: 0.9263
Epoch 36/75
771/782 [============================&gt;.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9257
Epoch 00036: val_loss did not improve from 0.19978
782/782 [==============================] - 3s 4ms/step - loss: 0.1929 - accuracy: 0.9257 - val_loss: 0.2009 - val_accuracy: 0.9261
Epoch 37/75
770/782 [============================&gt;.] - ETA: 0s - loss: 0.1958 - accuracy: 0.9281
Epoch 00037: val_loss did not improve from 0.19978
782/782 [==============================] - 3s 4ms/step - loss: 0.1957 - accuracy: 0.9281 - val_loss: 0.2085 - val_accuracy: 0.9225
Epoch 38/75
779/782 [============================&gt;.] - ETA: 0s - loss: 0.1916 - accuracy: 0.9277
Epoch 00038: val_loss did not improve from 0.19978
782/782 [==============================] - 4s 4ms/step - loss: 0.1915 - accuracy: 0.9277 - val_loss: 0.2106 - val_accuracy: 0.9198
Epoch 39/75
777/782 [============================&gt;.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9277
Epoch 00039: val_loss did not improve from 0.19978
782/782 [==============================] - 3s 4ms/step - loss: 0.1904 - accuracy: 0.9277 - val_loss: 0.2039 - val_accuracy: 0.9234
Epoch 40/75
775/782 [============================&gt;.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9278
Epoch 00040: val_loss improved from 0.19978 to 0.19934, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 5ms/step - loss: 0.1934 - accuracy: 0.9277 - val_loss: 0.1993 - val_accuracy: 0.9280
Epoch 41/75
773/782 [============================&gt;.] - ETA: 0s - loss: 0.1908 - accuracy: 0.9276
Epoch 00041: val_loss did not improve from 0.19934
782/782 [==============================] - 3s 4ms/step - loss: 0.1906 - accuracy: 0.9276 - val_loss: 0.2147 - val_accuracy: 0.9222
Epoch 42/75
781/782 [============================&gt;.] - ETA: 0s - loss: 0.1854 - accuracy: 0.9292
Epoch 00042: val_loss improved from 0.19934 to 0.19654, saving model to model.weights.best.hdf5
782/782 [==============================] - 4s 4ms/step - loss: 0.1854 - accuracy: 0.9292 - val_loss: 0.1965 - val_accuracy: 0.9274
Epoch 43/75
776/782 [============================&gt;.] - ETA: 0s - loss: 0.1839 - accuracy: 0.9295
Epoch 00043: val_loss did not improve from 0.19654
782/782 [==============================] - 4s 5ms/step - loss: 0.1839 - accuracy: 0.9295 - val_loss: 0.2033 - val_accuracy: 0.9266
Epoch 44/75
781/782 [============================&gt;.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9314
Epoch 00044: val_loss did not improve from 0.19654
782/782 [==============================] - 4s 5ms/step - loss: 0.1806 - accuracy: 0.9314 - val_loss: 0.2065 - val_accuracy: 0.9259
Epoch 45/75
777/782 [============================&gt;.] - ETA: 0s - loss: 0.1819 - accuracy: 0.9300
Epoch 00045: val_loss did not improve from 0.19654
782/782 [==============================] - 4s 5ms/step - loss: 0.1819 - accuracy: 0.9299 - val_loss: 0.2069 - val_accuracy: 0.9243
Epoch 46/75
778/782 [============================&gt;.] - ETA: 0s - loss: 0.1843 - accuracy: 0.9306
Epoch 00046: val_loss did not improve from 0.19654
782/782 [==============================] - 3s 4ms/step - loss: 0.1843 - accuracy: 0.9305 - val_loss: 0.2021 - val_accuracy: 0.9266
Epoch 47/75
779/782 [============================&gt;.] - ETA: 0s - loss: 0.1812 - accuracy: 0.9317
Epoch 00047: val_loss did not improve from 0.19654
782/782 [==============================] - 3s 4ms/step - loss: 0.1811 - accuracy: 0.9317 - val_loss: 0.2129 - val_accuracy: 0.9224
Epoch 48/75
772/782 [============================&gt;.] - ETA: 0s - loss: 0.1825 - accuracy: 0.9308
Epoch 00048: val_loss improved from 0.19654 to 0.19615, saving model to model.weights.best.hdf5
782/782 [==============================] - 3s 4ms/step - loss: 0.1831 - accuracy: 0.9306 - val_loss: 0.1961 - val_accuracy: 0.9275
Epoch 49/75
770/782 [============================&gt;.] - ETA: 0s - loss: 0.1768 - accuracy: 0.9327
Epoch 00049: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1770 - accuracy: 0.9327 - val_loss: 0.2090 - val_accuracy: 0.9242
Epoch 50/75
773/782 [============================&gt;.] - ETA: 0s - loss: 0.1779 - accuracy: 0.9322
Epoch 00050: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1783 - accuracy: 0.9320 - val_loss: 0.2262 - val_accuracy: 0.9188
Epoch 51/75
775/782 [============================&gt;.] - ETA: 0s - loss: 0.1773 - accuracy: 0.9322
Epoch 00051: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1772 - accuracy: 0.9322 - val_loss: 0.1996 - val_accuracy: 0.9280
Epoch 52/75
780/782 [============================&gt;.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9344
Epoch 00052: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1770 - accuracy: 0.9344 - val_loss: 0.2036 - val_accuracy: 0.9250
Epoch 53/75
776/782 [============================&gt;.] - ETA: 0s - loss: 0.1773 - accuracy: 0.9325
Epoch 00053: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1768 - accuracy: 0.9327 - val_loss: 0.2044 - val_accuracy: 0.9268
Epoch 54/75
773/782 [============================&gt;.] - ETA: 0s - loss: 0.1711 - accuracy: 0.9349
Epoch 00054: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1709 - accuracy: 0.9349 - val_loss: 0.2069 - val_accuracy: 0.9252
Epoch 55/75
779/782 [============================&gt;.] - ETA: 0s - loss: 0.1734 - accuracy: 0.9341
Epoch 00055: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1734 - accuracy: 0.9340 - val_loss: 0.2070 - val_accuracy: 0.9240
Epoch 56/75
775/782 [============================&gt;.] - ETA: 0s - loss: 0.1707 - accuracy: 0.9349
Epoch 00056: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1706 - accuracy: 0.9350 - val_loss: 0.2089 - val_accuracy: 0.9245
Epoch 57/75
770/782 [============================&gt;.] - ETA: 0s - loss: 0.1725 - accuracy: 0.9356
Epoch 00057: val_loss did not improve from 0.19615
782/782 [==============================] - 4s 4ms/step - loss: 0.1726 - accuracy: 0.9355 - val_loss: 0.1978 - val_accuracy: 0.9278
Epoch 58/75
775/782 [============================&gt;.] - ETA: 0s - loss: 0.1734 - accuracy: 0.9353
Epoch 00058: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1732 - accuracy: 0.9354 - val_loss: 0.1995 - val_accuracy: 0.9277
Epoch 59/75
772/782 [============================&gt;.] - ETA: 0s - loss: 0.1733 - accuracy: 0.9354
Epoch 00059: val_loss did not improve from 0.19615
782/782 [==============================] - 4s 4ms/step - loss: 0.1735 - accuracy: 0.9353 - val_loss: 0.2038 - val_accuracy: 0.9246
Epoch 60/75
771/782 [============================&gt;.] - ETA: 0s - loss: 0.1707 - accuracy: 0.9359
Epoch 00060: val_loss did not improve from 0.19615
782/782 [==============================] - 4s 4ms/step - loss: 0.1708 - accuracy: 0.9360 - val_loss: 0.2000 - val_accuracy: 0.9271
Epoch 61/75
773/782 [============================&gt;.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9360
Epoch 00061: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1662 - accuracy: 0.9362 - val_loss: 0.2032 - val_accuracy: 0.9277
Epoch 62/75
772/782 [============================&gt;.] - ETA: 0s - loss: 0.1669 - accuracy: 0.9361
Epoch 00062: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1667 - accuracy: 0.9361 - val_loss: 0.2034 - val_accuracy: 0.9252
Epoch 63/75
781/782 [============================&gt;.] - ETA: 0s - loss: 0.1696 - accuracy: 0.9345
Epoch 00063: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1696 - accuracy: 0.9345 - val_loss: 0.2069 - val_accuracy: 0.9231
Epoch 64/75
778/782 [============================&gt;.] - ETA: 0s - loss: 0.1637 - accuracy: 0.9385
Epoch 00064: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1637 - accuracy: 0.9386 - val_loss: 0.2018 - val_accuracy: 0.9250
Epoch 65/75
782/782 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.9381
Epoch 00065: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1651 - accuracy: 0.9381 - val_loss: 0.1974 - val_accuracy: 0.9301
Epoch 66/75
772/782 [============================&gt;.] - ETA: 0s - loss: 0.1654 - accuracy: 0.9379
Epoch 00066: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1655 - accuracy: 0.9378 - val_loss: 0.2007 - val_accuracy: 0.9280
Epoch 67/75
782/782 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.9376
Epoch 00067: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1652 - accuracy: 0.9376 - val_loss: 0.1969 - val_accuracy: 0.9277
Epoch 68/75
782/782 [==============================] - ETA: 0s - loss: 0.1646 - accuracy: 0.9379
Epoch 00068: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1646 - accuracy: 0.9379 - val_loss: 0.2065 - val_accuracy: 0.9285
Epoch 69/75
772/782 [============================&gt;.] - ETA: 0s - loss: 0.1661 - accuracy: 0.9377
Epoch 00069: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1658 - accuracy: 0.9378 - val_loss: 0.2019 - val_accuracy: 0.9294
Epoch 70/75
775/782 [============================&gt;.] - ETA: 0s - loss: 0.1628 - accuracy: 0.9379
Epoch 00070: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1624 - accuracy: 0.9381 - val_loss: 0.2045 - val_accuracy: 0.9296
Epoch 71/75
782/782 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9393
Epoch 00071: val_loss did not improve from 0.19615
782/782 [==============================] - 4s 4ms/step - loss: 0.1612 - accuracy: 0.9393 - val_loss: 0.2134 - val_accuracy: 0.9257
Epoch 72/75
782/782 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9383
Epoch 00072: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1647 - accuracy: 0.9383 - val_loss: 0.1976 - val_accuracy: 0.9291
Epoch 73/75
776/782 [============================&gt;.] - ETA: 0s - loss: 0.1642 - accuracy: 0.9384
Epoch 00073: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1648 - accuracy: 0.9381 - val_loss: 0.2027 - val_accuracy: 0.9292
Epoch 74/75
779/782 [============================&gt;.] - ETA: 0s - loss: 0.1609 - accuracy: 0.9387
Epoch 00074: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1608 - accuracy: 0.9388 - val_loss: 0.2112 - val_accuracy: 0.9269
Epoch 75/75
780/782 [============================&gt;.] - ETA: 0s - loss: 0.1645 - accuracy: 0.9378
Epoch 00075: val_loss did not improve from 0.19615
782/782 [==============================] - 3s 4ms/step - loss: 0.1644 - accuracy: 0.9378 - val_loss: 0.2055 - val_accuracy: 0.9275
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[26]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;tensorflow.python.keras.callbacks.History at 0x7f8a8b208710&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;model.weights.best.hdf5&#39;</span><span class="p">)</span>

<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Printing the test accuracy</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;Test accuracy:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
 Test accuracy: 0.9236999750137329
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 1.2 Train a ConvNet from scratch<a rel="noopener" class="anchor-link" href="#Task-1.2-Train-a-ConvNet-from-scratch">&#182;</a></h3><p><em>(weight ~2%)</em></p>
<p>Build a ConvNet to replace the densely connected network in Task 1.1. Report the classification accuracy on the test set. Aim to achieve higher accuracy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Reshaping input data from (28, 28) to (28, 28, 1)</span>
<span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>

<span class="c1">#we rescale the model for smoothness </span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="mf">255.0</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="mf">255.0</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="k">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="n">mean</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">scores</span><span class="p">,</span> <span class="n">histories</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(),</span> <span class="nb">list</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1">#select rows for train and test</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
  
<span class="c1">#Model Evaluation</span>
<span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&gt; </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">))</span>
 
<span class="c1">#storing scores</span>
<span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>
<span class="n">histories</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span><span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>

<span class="n">comparison_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;configuration&#39;</span><span class="p">,</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;ConvNet&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">comparison_df</span><span class="o">=</span><span class="n">comparison_df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">final_comparison_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;configuration&#39;</span><span class="p">,</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;ConvNet&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">final_comparison_df</span><span class="o">=</span><span class="n">final_comparison_df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.4119 - accuracy: 0.8533 - val_loss: 0.3245 - val_accuracy: 0.8852
Epoch 2/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.2734 - accuracy: 0.9021 - val_loss: 0.2776 - val_accuracy: 0.8991
Epoch 3/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.2220 - accuracy: 0.9197 - val_loss: 0.2724 - val_accuracy: 0.9038
Epoch 4/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.1796 - accuracy: 0.9352 - val_loss: 0.2706 - val_accuracy: 0.9078
Epoch 5/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.1456 - accuracy: 0.9470 - val_loss: 0.2770 - val_accuracy: 0.9093
Epoch 6/50
1500/1500 [==============================] - 6s 4ms/step - loss: 0.1183 - accuracy: 0.9574 - val_loss: 0.2850 - val_accuracy: 0.9091
Epoch 7/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0949 - accuracy: 0.9658 - val_loss: 0.3209 - val_accuracy: 0.9090
Epoch 8/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0812 - accuracy: 0.9707 - val_loss: 0.3359 - val_accuracy: 0.9070
Epoch 9/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0653 - accuracy: 0.9759 - val_loss: 0.3720 - val_accuracy: 0.9120
Epoch 10/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0536 - accuracy: 0.9806 - val_loss: 0.4021 - val_accuracy: 0.9095
Epoch 11/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0460 - accuracy: 0.9836 - val_loss: 0.4451 - val_accuracy: 0.9089
Epoch 12/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0397 - accuracy: 0.9857 - val_loss: 0.4685 - val_accuracy: 0.9085
Epoch 13/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0374 - accuracy: 0.9868 - val_loss: 0.5227 - val_accuracy: 0.9045
Epoch 14/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0290 - accuracy: 0.9899 - val_loss: 0.5499 - val_accuracy: 0.9043
Epoch 15/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0284 - accuracy: 0.9892 - val_loss: 0.5470 - val_accuracy: 0.9013
Epoch 16/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.6293 - val_accuracy: 0.9022
Epoch 17/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9912 - val_loss: 0.6339 - val_accuracy: 0.9009
Epoch 18/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0201 - accuracy: 0.9928 - val_loss: 0.6918 - val_accuracy: 0.9006
Epoch 19/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0188 - accuracy: 0.9927 - val_loss: 0.7150 - val_accuracy: 0.9053
Epoch 20/50
1500/1500 [==============================] - 5s 4ms/step - loss: 0.0166 - accuracy: 0.9939 - val_loss: 0.7431 - val_accuracy: 0.9024
Epoch 21/50
1500/1500 [==============================] - 6s 4ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.7199 - val_accuracy: 0.8969
Epoch 22/50
1500/1500 [==============================] - 5s 4ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.7671 - val_accuracy: 0.8966
Epoch 23/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0155 - accuracy: 0.9944 - val_loss: 0.7826 - val_accuracy: 0.8994
Epoch 24/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0146 - accuracy: 0.9946 - val_loss: 0.8505 - val_accuracy: 0.9002
Epoch 25/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.8458 - val_accuracy: 0.9004
Epoch 26/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0141 - accuracy: 0.9950 - val_loss: 0.9367 - val_accuracy: 0.8985
Epoch 27/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.9294 - val_accuracy: 0.8984
Epoch 28/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.8924 - val_accuracy: 0.8958
Epoch 29/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.9350 - val_accuracy: 0.9017
Epoch 30/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.9665 - val_accuracy: 0.8990
Epoch 31/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.9761 - val_accuracy: 0.9008
Epoch 32/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0102 - accuracy: 0.9960 - val_loss: 0.9735 - val_accuracy: 0.8994
Epoch 33/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 1.0909 - val_accuracy: 0.9021
Epoch 34/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 1.0589 - val_accuracy: 0.9022
Epoch 35/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.1484 - val_accuracy: 0.8999
Epoch 36/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0101 - accuracy: 0.9962 - val_loss: 1.1762 - val_accuracy: 0.8958
Epoch 37/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 1.1486 - val_accuracy: 0.9010
Epoch 38/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 1.0906 - val_accuracy: 0.8992
Epoch 39/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 1.1600 - val_accuracy: 0.8959
Epoch 40/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 1.1016 - val_accuracy: 0.9003
Epoch 41/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.1258 - val_accuracy: 0.8964
Epoch 42/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.1602 - val_accuracy: 0.8978
Epoch 43/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 1.2141 - val_accuracy: 0.8988
Epoch 44/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 1.1926 - val_accuracy: 0.8991
Epoch 45/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 1.2576 - val_accuracy: 0.9003
Epoch 46/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 1.2539 - val_accuracy: 0.9021
Epoch 47/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 1.2884 - val_accuracy: 0.9033
Epoch 48/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 1.2344 - val_accuracy: 0.8977
Epoch 49/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 1.2277 - val_accuracy: 0.8987
Epoch 50/50
1500/1500 [==============================] - 5s 3ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 1.4090 - val_accuracy: 0.8970
&gt; 88.930
Accuracy: 88.9299988746643
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 1.3 Build an input pipeline for data augmentation<a rel="noopener" class="anchor-link" href="#Task-1.3-Build-an-input-pipeline-for-data-augmentation">&#182;</a></h3><p><em>(weight ~4%)</em></p>
<p>Build a data preprocessing pipeline to perform data augmentation. (You may use Keras ImageDataGenerator or write your own transformations.)</p>
<ul>
<li><p>Report the new classification accuracy. Make sure that you use the same number of training epochs as in Task 1.2.</p>
</li>
<li><p>(Optional) Profile your input pipeline to identify the most time-consuming operation. What actions have you taken to address that slow operation? (<em>Hint: You may use the <a rel="noopener" href="https://github.com/tensorflow/profiler">TensorFlow Profiler</a>.</em>)</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="k">import</span> <span class="n">ImageDataGenerator</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="k">import</span> <span class="n">pyplot</span>

<span class="n">scores</span><span class="p">,</span> <span class="n">histories</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(),</span> <span class="nb">list</span><span class="p">()</span>

<span class="n">train_datagen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rotation_range</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="c1"># rotating</span>
                                  <span class="n">width_shift_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="c1"># horizontal shifting</span>
                                  <span class="n">height_shift_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="c1"># vertical shifting</span>
                                  <span class="n">horizontal_flip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># horizontal fliping</span>
                                  <span class="n">vertical_flip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1">#horizontal fliping</span>
                                  <span class="n">brightness_range</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">1.2</span><span class="p">])</span> <span class="c1"># marking brightness)</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_valid</span><span class="p">)</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="mi">10000</span><span class="p">:],</span> <span class="n">x_train</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span>
<span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="mi">10000</span><span class="p">:],</span> <span class="n">y_train</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span>

<span class="c1">#Training using ImageDataGenerator</span>
<span class="c1">#Same model used as above (Task 1.2)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_datagen</span><span class="o">.</span><span class="n">flow</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
                                     <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">),</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_valid</span><span class="p">,</span><span class="n">y_valid</span><span class="p">))</span>

<span class="c1">#Model Evaluation</span>
<span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span><span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>

<span class="c1">#storing scores</span>
<span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>
<span class="n">histories</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>

<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;ImageDataGenerator&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">comparison_df</span><span class="o">=</span><span class="n">comparison_df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;ImageDataGenerator&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">final_comparison_df</span><span class="o">=</span><span class="n">final_comparison_df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
1563/1563 [==============================] - 32s 21ms/step - loss: 14.8818 - accuracy: 0.0979 - val_loss: 2.3020 - val_accuracy: 0.1015
Epoch 2/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3077 - accuracy: 0.0978 - val_loss: 2.3027 - val_accuracy: 0.1022
Epoch 3/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3044 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.0988
Epoch 4/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3031 - accuracy: 0.1002 - val_loss: 2.3028 - val_accuracy: 0.0942
Epoch 5/50
1563/1563 [==============================] - 33s 21ms/step - loss: 2.3028 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.1019
Epoch 6/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3030 - accuracy: 0.1018 - val_loss: 2.3027 - val_accuracy: 0.0974
Epoch 7/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3029 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.0974
Epoch 8/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3029 - accuracy: 0.0984 - val_loss: 2.3028 - val_accuracy: 0.0989
Epoch 9/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0971 - val_loss: 2.3027 - val_accuracy: 0.1022
Epoch 10/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3030 - val_accuracy: 0.0942
Epoch 11/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3028 - val_accuracy: 0.0942
Epoch 12/50
1563/1563 [==============================] - 33s 21ms/step - loss: 2.3028 - accuracy: 0.0992 - val_loss: 2.3027 - val_accuracy: 0.0942
Epoch 13/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3029 - val_accuracy: 0.0990
Epoch 14/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0995 - val_loss: 2.3028 - val_accuracy: 0.0989
Epoch 15/50
1563/1563 [==============================] - 33s 21ms/step - loss: 2.3028 - accuracy: 0.0984 - val_loss: 2.3030 - val_accuracy: 0.0990
Epoch 16/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3028 - val_accuracy: 0.0990
Epoch 17/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.0942
Epoch 18/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3030 - val_accuracy: 0.0942
Epoch 19/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3027 - accuracy: 0.0973 - val_loss: 2.3028 - val_accuracy: 0.0942
Epoch 20/50
1563/1563 [==============================] - 32s 20ms/step - loss: 2.3028 - accuracy: 0.0990 - val_loss: 2.3027 - val_accuracy: 0.0942
Epoch 21/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.1001 - val_loss: 2.3029 - val_accuracy: 0.0942
Epoch 22/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0978 - val_loss: 2.3030 - val_accuracy: 0.0974
Epoch 23/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.1021
Epoch 24/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3029 - val_accuracy: 0.0990
Epoch 25/50
1563/1563 [==============================] - 33s 21ms/step - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3028 - val_accuracy: 0.0990
Epoch 26/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0962 - val_loss: 2.3027 - val_accuracy: 0.0974
Epoch 27/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.1021
Epoch 28/50
1563/1563 [==============================] - 33s 21ms/step - loss: 2.3028 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.0989
Epoch 29/50
1563/1563 [==============================] - 33s 21ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3028 - val_accuracy: 0.0942
Epoch 30/50
1563/1563 [==============================] - 33s 21ms/step - loss: 2.3027 - accuracy: 0.0990 - val_loss: 2.3030 - val_accuracy: 0.0942
Epoch 31/50
1563/1563 [==============================] - 33s 21ms/step - loss: 2.3028 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.1019
Epoch 32/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.0974
Epoch 33/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0965 - val_loss: 2.3029 - val_accuracy: 0.0990
Epoch 34/50
1563/1563 [==============================] - 33s 21ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.0942
Epoch 35/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.0990
Epoch 36/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3029 - val_accuracy: 0.0990
Epoch 37/50
1563/1563 [==============================] - 32s 20ms/step - loss: 2.3028 - accuracy: 0.1000 - val_loss: 2.3028 - val_accuracy: 0.0942
Epoch 38/50
1563/1563 [==============================] - 32s 20ms/step - loss: 2.3028 - accuracy: 0.1003 - val_loss: 2.3026 - val_accuracy: 0.1027
Epoch 39/50
1563/1563 [==============================] - 32s 20ms/step - loss: 2.3028 - accuracy: 0.0975 - val_loss: 2.3027 - val_accuracy: 0.1019
Epoch 40/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0965 - val_loss: 2.3028 - val_accuracy: 0.1000
Epoch 41/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3028 - val_accuracy: 0.0974
Epoch 42/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3027 - val_accuracy: 0.1000
Epoch 43/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.1019
Epoch 44/50
1563/1563 [==============================] - 33s 21ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3029 - val_accuracy: 0.0942
Epoch 45/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3027 - accuracy: 0.0987 - val_loss: 2.3031 - val_accuracy: 0.0974
Epoch 46/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3029 - val_accuracy: 0.0942
Epoch 47/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0976 - val_loss: 2.3028 - val_accuracy: 0.0974
Epoch 48/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3027 - accuracy: 0.0997 - val_loss: 2.3025 - val_accuracy: 0.1016
Epoch 49/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0977 - val_loss: 2.3028 - val_accuracy: 0.0989
Epoch 50/50
1563/1563 [==============================] - 32s 21ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3028 - val_accuracy: 0.0942
Accuracy 10.000000149011612
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 1.4 Fashion-MNIST with transfer learning<a rel="noopener" class="anchor-link" href="#Task-1.4-Fashion-MNIST-with-transfer-learning">&#182;</a></h3><p><em>(weight ~6%)</em></p>
<p>Use a pretrained model as the convolutional base to improve the classification performance. (Hint: You may use models in Keras Applications or those in the TensorFlow Hub.)</p>
<ul>
<li>Try both with fine-tuning and without fine-tuning.</li>
<li>Report the model performance as before.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.applications.vgg16</span> <span class="k">import</span> <span class="n">VGG16</span>
<span class="kn">from</span> <span class="nn">keras.applications.vgg16</span> <span class="k">import</span> <span class="n">preprocess_input</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="k">import</span> <span class="n">keras</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># transform to rgb as required by VGG</span>
<span class="n">train_img</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">grayscale_to_rgb</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span> 
<span class="n">test_img</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">grayscale_to_rgb</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>

<span class="c1">#resize to minimum size of (32x32)</span>
<span class="n">train_img</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize_with_pad</span><span class="p">(</span><span class="n">train_img</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">)</span>
<span class="n">test_img</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize_with_pad</span><span class="p">(</span><span class="n">test_img</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">)</span>

<span class="n">train_img</span> <span class="o">=</span> <span class="n">train_img</span> <span class="o">/</span> <span class="mf">255.</span>
<span class="n">test_img</span> <span class="o">=</span> <span class="n">test_img</span> <span class="o">/</span> <span class="mf">255.</span>

<span class="c1">#preprocessing as required by VGG16</span>
<span class="n">train_img</span><span class="o">=</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">train_img</span><span class="p">)</span>
<span class="n">test_img</span><span class="o">=</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">test_img</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#With Fine Tuning</span>

<span class="kn">from</span> <span class="nn">keras.applications.vgg16</span> <span class="k">import</span> <span class="n">VGG16</span>
<span class="kn">from</span> <span class="nn">keras.applications.vgg16</span> <span class="k">import</span> <span class="n">preprocess_input</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="k">import</span> <span class="n">keras</span>


<span class="c1">#using model without last layers</span>
<span class="n">vgg16</span><span class="o">=</span><span class="n">VGG16</span><span class="p">(</span><span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>

<span class="n">layer_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">layer</span><span class="p">)</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">vgg16</span><span class="o">.</span><span class="n">layers</span><span class="p">])</span>

<span class="c1">#stop at block3_pool and get output</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">layer_dict</span><span class="p">[</span><span class="s1">&#39;block3_pool&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">output</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">final</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">vgg16</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">final</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="mi">10</span><span class="p">]:</span>
  <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">final</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">final</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_img</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,)</span>

<span class="c1">#Model Evaluation</span>
<span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">final</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_img</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>

<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;Transfer Learning with Fine Tuning&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">comparison_df</span><span class="o">=</span><span class="n">comparison_df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;Transfer Learning with Fine Tuning&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">final_comparison_df</span><span class="o">=</span><span class="n">final_comparison_df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5
58892288/58889256 [==============================] - 0s 0us/step
Epoch 1/50
188/188 [==============================] - 3s 15ms/step - loss: 12.3160 - accuracy: 0.1000 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 2/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 3/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 4/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 5/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 6/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 7/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 8/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 9/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 10/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 11/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 12/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 13/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 14/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 15/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 16/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 17/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 18/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 19/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 20/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 21/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 22/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 23/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 24/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 25/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 26/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 27/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 28/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 29/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 30/50
188/188 [==============================] - 2s 13ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 31/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 32/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 33/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 34/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 35/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 36/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 37/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 38/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 39/50
188/188 [==============================] - 2s 13ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 40/50
188/188 [==============================] - 2s 13ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 41/50
188/188 [==============================] - 2s 13ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 42/50
188/188 [==============================] - 2s 13ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 43/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 44/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 45/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 46/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 47/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 48/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3866 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 49/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Epoch 50/50
188/188 [==============================] - 2s 12ms/step - loss: 12.3867 - accuracy: 0.1004 - val_loss: 12.3598 - val_accuracy: 0.0983
Accuracy: 10.000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#Without fine tuning</span>

<span class="kn">from</span> <span class="nn">keras.applications.vgg16</span> <span class="k">import</span> <span class="n">VGG16</span>

<span class="n">base_model</span> <span class="o">=</span> <span class="n">VGG16</span><span class="p">(</span>
    <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span>  <span class="c1"># Load weights pre-trained on ImageNet.</span>
    <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">base_model</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="c1"># We make sure that the base_model is running in inference mode here,</span>
<span class="c1"># by passing `training=False`.</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">base_model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># Convert features of shape `base_model.output_shape[1:]` to vectors</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="c1"># A Dense classifier</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(),</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_img</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1">#Model Evaluation</span>
<span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">final</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_img</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>

<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;Transfer Learning without Fine Tuning&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">comparison_df</span><span class="o">=</span><span class="n">comparison_df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;Transfer Learning without Fine Tuning&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">final_comparison_df</span><span class="o">=</span><span class="n">final_comparison_df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 2/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 3/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 4/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 5/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 6/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 7/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 8/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 9/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 10/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 11/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 12/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 13/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 14/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 15/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 16/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 17/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 18/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 19/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 20/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 21/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 22/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 23/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 24/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 25/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 26/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 27/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 28/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 29/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 30/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 31/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 32/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 33/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 34/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 35/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 36/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 37/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 38/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 39/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 40/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 41/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 42/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 43/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 44/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 45/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 46/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 47/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 48/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 49/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Epoch 50/50
1500/1500 [==============================] - 12s 8ms/step - loss: 5.2859 - accuracy: 0.1011 - val_loss: 5.3716 - val_accuracy: 0.0957
Accuracy: 10.000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 1.5 Performance comparison<a rel="noopener" class="anchor-link" href="#Task-1.5-Performance-comparison">&#182;</a></h3><p><em>(weight ~4%)</em></p>
<p>Record the test accuracy achieved at different training configurations above. Which method achieved the highest accuracy? Why did it work better for this problem?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">comparison_df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[10]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>configuration</th>
      <th>accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ConvNet</td>
      <td>88.929999</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ImageDataGenerator</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Transfer Learning with Fine Tuning</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Transfer Learning without Fine Tuning</td>
      <td>10.000000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">highest</span><span class="o">=</span><span class="n">comparison_df</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The highest accuracy is observed for:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">comparison_df</span><span class="p">[</span><span class="n">comparison_df</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">highest</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>The highest accuracy is observed for:

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[11]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>configuration</th>
      <th>accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ConvNet</td>
      <td>88.929999</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CNN is considered to perform best because of it&#39;s architecture. </span><span class="se">\n</span><span class="s2">The system first generates filtered invariant features using convolution of images and then passes it to the next layer &quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>CNN is considered to perform best because of it&#39;s architecture. 
The system first generates filtered invariant features using convolution of images and then passes it to the next layer 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2><strong>End of task 1</strong><a rel="noopener" class="anchor-link" href="#End-of-task-1">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Task 2 Fast training of deep networks<a rel="noopener" class="anchor-link" href="#Task-2-Fast-training-of-deep-networks">&#182;</a></h2><p><em>(weight ~16%)</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h6>Task 2.1 Train a highly accurate network for CIFAR10<a rel="noopener" class="anchor-link" href="#Task-2.1-Train-a-highly-accurate-network-for-CIFAR10">&#182;</a></h6><p><em>(weight ~6%, each subquestion worths ~2%)</em></p>
<p>In this task, you will train deep neural networks on the <a rel="noopener" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10 dataset</a>. Compared with the datasets that you have worked on so far, CIFAR10 represents a relatively larger multi-class classification problem and presents a great opportunity for you to solve a &quot;harder&quot; problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4>Task 2.1.1 Document the hardware used<a rel="noopener" class="anchor-link" href="#Task-2.1.1-Document-the-hardware-used">&#182;</a></h4><p>Before you start, write down your hardware specifications, including</p>
<ul>
<li>the GPU model, the number of GPUs, and the GPU memory</li>
<li>the CPU model, the number of CPUs, and the CPU clock speed</li>
</ul>
<p>(Hint: you may find commands like <code>nvidia-smi</code>, <code>lscpu</code> or <code>psutil</code> useful.)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install gputil
<span class="kn">import</span> <span class="nn">GPUtil</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="k">import</span> <span class="n">tabulate</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">40</span><span class="p">,</span> <span class="s2">&quot;GPU Details&quot;</span><span class="p">,</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">gpus</span> <span class="o">=</span> <span class="n">GPUtil</span><span class="o">.</span><span class="n">getGPUs</span><span class="p">()</span>
<span class="n">list_gpus</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="n">gpus</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU Number:&quot;</span><span class="p">,</span> <span class="n">count</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># name of GPU</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU Name:&quot;</span><span class="p">,</span><span class="n">gpu</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="c1"># get free memory in MB format</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU Free Memory:&quot;</span><span class="p">,</span> <span class="n">gpu</span><span class="o">.</span><span class="n">memoryFree</span><span class="p">)</span>
    <span class="c1"># get used memory</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU Used Memory:&quot;</span><span class="p">,</span> <span class="n">gpu</span><span class="o">.</span><span class="n">memoryUsed</span><span class="p">)</span>
    <span class="c1"># get total memory</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU Total Memory:&quot;</span><span class="p">,</span> <span class="n">gpu</span><span class="o">.</span><span class="n">memoryTotal</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting gputil
  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz
Building wheels for collected packages: gputil
  Building wheel for gputil (setup.py) ... done
  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=bfa3625c7de14305bda07b3e1a2165146041eb1f113436be08ec5bcf0b08d58b
  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd
Successfully built gputil
Installing collected packages: gputil
Successfully installed gputil-1.4.0
======================================== GPU Details ========================================
GPU Number: 1
GPU Name: Tesla P100-PCIE-16GB
GPU Free Memory: 11479.0
GPU Used Memory: 4801.0
GPU Total Memory: 16280.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install psutil
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">psutil</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">40</span><span class="p">,</span> <span class="s2">&quot;CPU Info&quot;</span><span class="p">,</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="c1">#processor name</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Processor Name: &quot;</span><span class="p">,</span><span class="n">platform</span><span class="o">.</span><span class="n">processor</span><span class="p">())</span>
<span class="c1"># number of cores</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total cores:&quot;</span><span class="p">,</span> <span class="n">psutil</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">(</span><span class="n">logical</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="c1"># CPU frequencies</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CPU Frequency: &quot;</span><span class="p">,</span><span class="n">psutil</span><span class="o">.</span><span class="n">cpu_freq</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)
======================================== CPU Info ========================================
Processor Name:  x86_64
Total cores: 4
CPU Frequency:  None
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4>Task 2.1.2 Train a &quot;shallow&quot; ConvNet<a rel="noopener" class="anchor-link" href="#Task-2.1.2-Train-a-&quot;shallow&quot;-ConvNet">&#182;</a></h4><p>Build a ConvNet with fewer than 10 layers. Train the network until it converges. You will use this network as a baseline for the later experiments.</p>
<ul>
<li>Plot the training and validation history. </li>
<li>Report the testing accuracy. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">x_train_c</span><span class="p">,</span> <span class="n">y_train_c</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test_c</span><span class="p">,</span> <span class="n">y_test_c</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">y_train_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train_c</span><span class="p">)</span>
<span class="n">y_test_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test_c</span><span class="p">)</span>

<span class="c1">#we rescale the model for smoothness </span>
<span class="n">x_train_c</span> <span class="o">=</span> <span class="n">x_train_c</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="mf">255.0</span>
<span class="n">x_test_c</span> <span class="o">=</span> <span class="n">x_test_c</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="mf">255.0</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz
170500096/170498071 [==============================] - 3s 0us/step
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="k">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="c1">#Compile</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_c</span><span class="p">,</span> <span class="n">y_train_c</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="c1">#Model Evaluation</span>
<span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test_c</span><span class="p">,</span> <span class="n">y_test_c</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>

<span class="c1">#Model Acc</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1">#Model Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">comparison_df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;configuration&#39;</span><span class="p">,</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;Shallow ConvNet&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">comparison_df2</span><span class="o">=</span><span class="n">comparison_df2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;Shallow ConvNet&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">final_comparison_df</span><span class="o">=</span><span class="n">final_comparison_df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
1250/1250 [==============================] - 7s 6ms/step - loss: 1.7630 - accuracy: 0.3616 - val_loss: 1.4968 - val_accuracy: 0.4689
Epoch 2/50
1250/1250 [==============================] - 7s 5ms/step - loss: 1.3923 - accuracy: 0.4985 - val_loss: 1.3351 - val_accuracy: 0.5224
Epoch 3/50
1250/1250 [==============================] - 7s 5ms/step - loss: 1.2216 - accuracy: 0.5655 - val_loss: 1.1341 - val_accuracy: 0.6032
Epoch 4/50
1250/1250 [==============================] - 7s 5ms/step - loss: 1.0933 - accuracy: 0.6141 - val_loss: 1.0989 - val_accuracy: 0.6143
Epoch 5/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.9972 - accuracy: 0.6508 - val_loss: 0.9987 - val_accuracy: 0.6485
Epoch 6/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.9118 - accuracy: 0.6801 - val_loss: 0.9829 - val_accuracy: 0.6581
Epoch 7/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.8422 - accuracy: 0.7060 - val_loss: 0.9533 - val_accuracy: 0.6681
Epoch 8/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.7777 - accuracy: 0.7286 - val_loss: 0.8751 - val_accuracy: 0.6997
Epoch 9/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.7221 - accuracy: 0.7466 - val_loss: 0.9067 - val_accuracy: 0.6870
Epoch 10/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.6665 - accuracy: 0.7660 - val_loss: 0.8489 - val_accuracy: 0.7106
Epoch 11/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.6126 - accuracy: 0.7852 - val_loss: 0.8357 - val_accuracy: 0.7171
Epoch 12/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.5672 - accuracy: 0.8023 - val_loss: 0.9390 - val_accuracy: 0.6935
Epoch 13/50
1250/1250 [==============================] - 6s 5ms/step - loss: 0.5271 - accuracy: 0.8161 - val_loss: 0.8665 - val_accuracy: 0.7205
Epoch 14/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.4742 - accuracy: 0.8346 - val_loss: 0.9117 - val_accuracy: 0.7182
Epoch 15/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.4368 - accuracy: 0.8486 - val_loss: 0.9037 - val_accuracy: 0.7204
Epoch 16/50
1250/1250 [==============================] - 6s 5ms/step - loss: 0.3954 - accuracy: 0.8616 - val_loss: 0.9231 - val_accuracy: 0.7224
Epoch 17/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.3542 - accuracy: 0.8758 - val_loss: 0.9142 - val_accuracy: 0.7311
Epoch 18/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.3168 - accuracy: 0.8868 - val_loss: 0.9677 - val_accuracy: 0.7255
Epoch 19/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.2794 - accuracy: 0.9017 - val_loss: 1.0790 - val_accuracy: 0.7174
Epoch 20/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.2446 - accuracy: 0.9132 - val_loss: 1.0989 - val_accuracy: 0.7202
Epoch 21/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.2139 - accuracy: 0.9240 - val_loss: 1.1237 - val_accuracy: 0.7210
Epoch 22/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.1917 - accuracy: 0.9316 - val_loss: 1.2277 - val_accuracy: 0.7169
Epoch 23/50
1250/1250 [==============================] - 6s 5ms/step - loss: 0.1657 - accuracy: 0.9401 - val_loss: 1.3569 - val_accuracy: 0.7032
Epoch 24/50
1250/1250 [==============================] - 6s 5ms/step - loss: 0.1424 - accuracy: 0.9495 - val_loss: 1.3337 - val_accuracy: 0.7168
Epoch 25/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.1389 - accuracy: 0.9518 - val_loss: 1.3545 - val_accuracy: 0.7130
Epoch 26/50
1250/1250 [==============================] - 6s 5ms/step - loss: 0.1114 - accuracy: 0.9608 - val_loss: 1.3771 - val_accuracy: 0.7207
Epoch 27/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.1135 - accuracy: 0.9590 - val_loss: 1.4776 - val_accuracy: 0.7107
Epoch 28/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0881 - accuracy: 0.9701 - val_loss: 1.5189 - val_accuracy: 0.7203
Epoch 29/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0765 - accuracy: 0.9728 - val_loss: 1.5721 - val_accuracy: 0.7265
Epoch 30/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0764 - accuracy: 0.9736 - val_loss: 1.7157 - val_accuracy: 0.7073
Epoch 31/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0879 - accuracy: 0.9688 - val_loss: 1.6869 - val_accuracy: 0.7171
Epoch 32/50
1250/1250 [==============================] - 6s 5ms/step - loss: 0.0801 - accuracy: 0.9721 - val_loss: 1.6825 - val_accuracy: 0.7304
Epoch 33/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0512 - accuracy: 0.9831 - val_loss: 1.7873 - val_accuracy: 0.7225
Epoch 34/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0666 - accuracy: 0.9764 - val_loss: 1.7551 - val_accuracy: 0.7172
Epoch 35/50
1250/1250 [==============================] - 6s 5ms/step - loss: 0.0544 - accuracy: 0.9811 - val_loss: 1.8553 - val_accuracy: 0.7236
Epoch 36/50
1250/1250 [==============================] - 6s 5ms/step - loss: 0.0497 - accuracy: 0.9824 - val_loss: 1.7900 - val_accuracy: 0.7267
Epoch 37/50
1250/1250 [==============================] - 6s 5ms/step - loss: 0.0545 - accuracy: 0.9817 - val_loss: 1.8635 - val_accuracy: 0.7171
Epoch 38/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0430 - accuracy: 0.9851 - val_loss: 1.9113 - val_accuracy: 0.7268
Epoch 39/50
1250/1250 [==============================] - 6s 5ms/step - loss: 0.0478 - accuracy: 0.9829 - val_loss: 1.9726 - val_accuracy: 0.7184
Epoch 40/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0591 - accuracy: 0.9800 - val_loss: 1.9160 - val_accuracy: 0.7186
Epoch 41/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 1.9819 - val_accuracy: 0.7311
Epoch 42/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0370 - accuracy: 0.9870 - val_loss: 1.9806 - val_accuracy: 0.7253
Epoch 43/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0267 - accuracy: 0.9914 - val_loss: 2.0613 - val_accuracy: 0.7267
Epoch 44/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 2.0990 - val_accuracy: 0.7335
Epoch 45/50
1250/1250 [==============================] - 6s 5ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 2.2667 - val_accuracy: 0.7253
Epoch 46/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0295 - accuracy: 0.9899 - val_loss: 2.0924 - val_accuracy: 0.7226
Epoch 47/50
1250/1250 [==============================] - 7s 6ms/step - loss: 0.0353 - accuracy: 0.9875 - val_loss: 2.4044 - val_accuracy: 0.7050
Epoch 48/50
1250/1250 [==============================] - 7s 6ms/step - loss: 0.0424 - accuracy: 0.9852 - val_loss: 2.1267 - val_accuracy: 0.7182
Epoch 49/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0307 - accuracy: 0.9898 - val_loss: 2.3242 - val_accuracy: 0.7201
Epoch 50/50
1250/1250 [==============================] - 7s 5ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 2.2740 - val_accuracy: 0.7241
Accuracy: 70.980
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4>Task 2.1.3 Train a ResNet<a rel="noopener" class="anchor-link" href="#Task-2.1.3-Train-a-ResNet">&#182;</a></h4><p>Train a residual neural network (ResNet) on the CIFAR10 training data and report the test accuracy and the training time.</p>
<p>The ResNet is a popular network architecture for image classification. You may find more information about how ResNet works by reading this <a rel="noopener" href="https://arxiv.org/abs/1512.03385">paper</a>.</p>
<p><em>(You may implement a resnet model or use an existing implementation. In either case, you should not use pretrained network weights.)</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">GlobalAveragePooling2D</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">add</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">applications</span>

<span class="n">base_model</span> <span class="o">=</span> <span class="n">applications</span><span class="o">.</span><span class="n">resnet50</span><span class="o">.</span><span class="n">ResNet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">base_model</span><span class="o">.</span><span class="n">output</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.7</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">layer_output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span> <span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">base_model</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">layer_output</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_c</span><span class="p">,</span> <span class="n">y_train_c</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1">#Model Evaluation</span>
<span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test_c</span><span class="p">,</span> <span class="n">y_test_c</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>

<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;ResNet&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">comparison_df2</span><span class="o">=</span><span class="n">comparison_df2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;ResNet&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">final_comparison_df</span><span class="o">=</span><span class="n">final_comparison_df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
625/625 [==============================] - 27s 43ms/step - loss: 2.7553 - accuracy: 0.2700 - val_loss: 349.6628 - val_accuracy: 0.1017
Epoch 2/50
625/625 [==============================] - 26s 42ms/step - loss: 2.7270 - accuracy: 0.2219 - val_loss: 6.0092 - val_accuracy: 0.2493
Epoch 3/50
625/625 [==============================] - 26s 42ms/step - loss: 2.3637 - accuracy: 0.3068 - val_loss: 2.1110 - val_accuracy: 0.2125
Epoch 4/50
625/625 [==============================] - 26s 42ms/step - loss: 2.1737 - accuracy: 0.3230 - val_loss: 2.0469 - val_accuracy: 0.3455
Epoch 5/50
625/625 [==============================] - 26s 42ms/step - loss: 2.0641 - accuracy: 0.3858 - val_loss: 19.3764 - val_accuracy: 0.2603
Epoch 6/50
625/625 [==============================] - 26s 42ms/step - loss: 1.9847 - accuracy: 0.4010 - val_loss: 2.1783 - val_accuracy: 0.3259
Epoch 7/50
625/625 [==============================] - 26s 42ms/step - loss: 1.8661 - accuracy: 0.4336 - val_loss: 3.6815 - val_accuracy: 0.3830
Epoch 8/50
625/625 [==============================] - 26s 42ms/step - loss: 2.2509 - accuracy: 0.3733 - val_loss: 1.8639 - val_accuracy: 0.3757
Epoch 9/50
625/625 [==============================] - 26s 42ms/step - loss: 2.1133 - accuracy: 0.4072 - val_loss: 2.0818 - val_accuracy: 0.4116
Epoch 10/50
625/625 [==============================] - 26s 42ms/step - loss: 1.9356 - accuracy: 0.4431 - val_loss: 2.1075 - val_accuracy: 0.4163
Epoch 11/50
625/625 [==============================] - 26s 42ms/step - loss: 1.8990 - accuracy: 0.4606 - val_loss: 29.6583 - val_accuracy: 0.3407
Epoch 12/50
625/625 [==============================] - 26s 42ms/step - loss: 1.9374 - accuracy: 0.4482 - val_loss: 39.8480 - val_accuracy: 0.3181
Epoch 13/50
625/625 [==============================] - 26s 42ms/step - loss: 1.8342 - accuracy: 0.4629 - val_loss: 6.2437 - val_accuracy: 0.4391
Epoch 14/50
625/625 [==============================] - 26s 42ms/step - loss: 1.8831 - accuracy: 0.4525 - val_loss: 2.0843 - val_accuracy: 0.3605
Epoch 15/50
625/625 [==============================] - 26s 42ms/step - loss: 1.7229 - accuracy: 0.4889 - val_loss: 2.4599 - val_accuracy: 0.1691
Epoch 16/50
625/625 [==============================] - 26s 42ms/step - loss: 1.6949 - accuracy: 0.4836 - val_loss: 6.4509 - val_accuracy: 0.2924
Epoch 17/50
625/625 [==============================] - 26s 42ms/step - loss: 1.6868 - accuracy: 0.5024 - val_loss: 1.4282 - val_accuracy: 0.5106
Epoch 18/50
625/625 [==============================] - 26s 42ms/step - loss: 1.5635 - accuracy: 0.5397 - val_loss: 1.6716 - val_accuracy: 0.3972
Epoch 19/50
625/625 [==============================] - 26s 42ms/step - loss: 1.4390 - accuracy: 0.5550 - val_loss: 244.5898 - val_accuracy: 0.2560
Epoch 20/50
625/625 [==============================] - 26s 42ms/step - loss: 1.3892 - accuracy: 0.5742 - val_loss: 1.7333 - val_accuracy: 0.4456
Epoch 21/50
625/625 [==============================] - 26s 42ms/step - loss: 1.2995 - accuracy: 0.5925 - val_loss: 1.3175 - val_accuracy: 0.5624
Epoch 22/50
625/625 [==============================] - 26s 42ms/step - loss: 1.3898 - accuracy: 0.5693 - val_loss: 5.4387 - val_accuracy: 0.4959
Epoch 23/50
625/625 [==============================] - 26s 42ms/step - loss: 1.2812 - accuracy: 0.6060 - val_loss: 193.3368 - val_accuracy: 0.1473
Epoch 24/50
625/625 [==============================] - 26s 42ms/step - loss: 1.5209 - accuracy: 0.5071 - val_loss: 2.5338 - val_accuracy: 0.3105
Epoch 25/50
625/625 [==============================] - 26s 42ms/step - loss: 1.3774 - accuracy: 0.5479 - val_loss: 1.3649 - val_accuracy: 0.5843
Epoch 26/50
625/625 [==============================] - 26s 42ms/step - loss: 1.1617 - accuracy: 0.6233 - val_loss: 2.2878 - val_accuracy: 0.3060
Epoch 27/50
625/625 [==============================] - 26s 42ms/step - loss: 1.2900 - accuracy: 0.5700 - val_loss: 1.3470 - val_accuracy: 0.5444
Epoch 28/50
625/625 [==============================] - 26s 42ms/step - loss: 1.1533 - accuracy: 0.6139 - val_loss: 1.2446 - val_accuracy: 0.5755
Epoch 29/50
625/625 [==============================] - 26s 42ms/step - loss: 1.0979 - accuracy: 0.6292 - val_loss: 1.7579 - val_accuracy: 0.4039
Epoch 30/50
625/625 [==============================] - 26s 42ms/step - loss: 1.0516 - accuracy: 0.6444 - val_loss: 1.1126 - val_accuracy: 0.6111
Epoch 31/50
625/625 [==============================] - 26s 42ms/step - loss: 1.0455 - accuracy: 0.6415 - val_loss: 2.2751 - val_accuracy: 0.2999
Epoch 32/50
625/625 [==============================] - 26s 42ms/step - loss: 1.1671 - accuracy: 0.5998 - val_loss: 1.1480 - val_accuracy: 0.6194
Epoch 33/50
625/625 [==============================] - 26s 42ms/step - loss: 0.8953 - accuracy: 0.6902 - val_loss: 1.1508 - val_accuracy: 0.6166
Epoch 34/50
625/625 [==============================] - 26s 42ms/step - loss: 0.9252 - accuracy: 0.6848 - val_loss: 1.0234 - val_accuracy: 0.6590
Epoch 35/50
625/625 [==============================] - 26s 42ms/step - loss: 0.8425 - accuracy: 0.7162 - val_loss: 1.0447 - val_accuracy: 0.6583
Epoch 36/50
625/625 [==============================] - 26s 42ms/step - loss: 1.0612 - accuracy: 0.6381 - val_loss: 1.2583 - val_accuracy: 0.5939
Epoch 37/50
625/625 [==============================] - 26s 42ms/step - loss: 0.9192 - accuracy: 0.6882 - val_loss: 1.1464 - val_accuracy: 0.6353
Epoch 38/50
625/625 [==============================] - 26s 42ms/step - loss: 0.8002 - accuracy: 0.7261 - val_loss: 1.3879 - val_accuracy: 0.6105
Epoch 39/50
625/625 [==============================] - 26s 42ms/step - loss: 0.7464 - accuracy: 0.7412 - val_loss: 1.1417 - val_accuracy: 0.6749
Epoch 40/50
625/625 [==============================] - 26s 42ms/step - loss: 0.9205 - accuracy: 0.6833 - val_loss: 1.1421 - val_accuracy: 0.6309
Epoch 41/50
625/625 [==============================] - 26s 42ms/step - loss: 1.0739 - accuracy: 0.6278 - val_loss: 1.6424 - val_accuracy: 0.4602
Epoch 42/50
625/625 [==============================] - 26s 42ms/step - loss: 1.0148 - accuracy: 0.6461 - val_loss: 1.4337 - val_accuracy: 0.6517
Epoch 43/50
625/625 [==============================] - 26s 42ms/step - loss: 0.7605 - accuracy: 0.7351 - val_loss: 1.1567 - val_accuracy: 0.6895
Epoch 44/50
625/625 [==============================] - 26s 42ms/step - loss: 0.6375 - accuracy: 0.7783 - val_loss: 2.6452 - val_accuracy: 0.6898
Epoch 45/50
625/625 [==============================] - 26s 42ms/step - loss: 0.5954 - accuracy: 0.7940 - val_loss: 1.1800 - val_accuracy: 0.6719
Epoch 46/50
625/625 [==============================] - 26s 42ms/step - loss: 0.5243 - accuracy: 0.8206 - val_loss: 2.1845 - val_accuracy: 0.6925
Epoch 47/50
625/625 [==============================] - 26s 42ms/step - loss: 0.5530 - accuracy: 0.8098 - val_loss: 3.8326 - val_accuracy: 0.3588
Epoch 48/50
625/625 [==============================] - 26s 42ms/step - loss: 0.5459 - accuracy: 0.8106 - val_loss: 1.9642 - val_accuracy: 0.6721
Epoch 49/50
625/625 [==============================] - 26s 42ms/step - loss: 0.5468 - accuracy: 0.8116 - val_loss: 1.0355 - val_accuracy: 0.6619
Epoch 50/50
625/625 [==============================] - 26s 42ms/step - loss: 0.4562 - accuracy: 0.8429 - val_loss: 2.1358 - val_accuracy: 0.6701
Accuracy: 67.320
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 2.2 Fast training of ResNet<a rel="noopener" class="anchor-link" href="#Task-2.2-Fast-training-of-ResNet">&#182;</a></h3><p><em>(weight ~5%)</em></p>
<p>In this task, you will experiment with different ways to reduce the time for training your ResNet on CIFAR10. There are different ways to speed up neural network training; below are two ideas. Please select at least one idea to implement. Explain the experiment steps and report the final performance and training time.</p>
<h4>Option 1. Learning rate schedule<a rel="noopener" class="anchor-link" href="#Option-1.-Learning-rate-schedule">&#182;</a></h4><p>Use a learning rate schedule for the training. Some popular learning rate schedules include</p>
<ul>
<li>the Step Decay learning rate (e.g., see <a rel="noopener" href="https://github.com/kuangliu/pytorch-cifar">here</a>)</li>
<li><a rel="noopener" href="https://arxiv.org/abs/1506.01186">Cyclical learning rates</a></li>
<li><a rel="noopener" href="https://openreview.net/forum?id=rJg8TeSFDH">The exponential learning rate</a> </li>
</ul>
<p>Also Keras provides <a rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules">some convenient functions</a> that you can use.</p>
<h4>Option 2. Look ahead optimiser<a rel="noopener" class="anchor-link" href="#Option-2.-Look-ahead-optimiser">&#182;</a></h4><p>Read <a rel="noopener" href="https://arxiv.org/abs/1907.08610">this paper</a> and implement the Lookahead optimiser.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">keras.optimizers.schedules</span> <span class="k">import</span> <span class="n">ExponentialDecay</span>
<span class="n">initial_learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">lr_schedule</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">ExponentialDecay</span><span class="p">(</span>
    <span class="n">initial_learning_rate</span><span class="p">,</span>
    <span class="n">decay_steps</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
    <span class="n">decay_rate</span><span class="o">=</span><span class="mf">0.96</span><span class="p">,</span>
    <span class="n">staircase</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># decayed_learning_rate = learning_rate * decay_rate ^ (global_step / decay_steps)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">applications</span><span class="o">.</span><span class="n">resnet50</span><span class="o">.</span><span class="n">ResNet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">base_model</span><span class="o">.</span><span class="n">output</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.7</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">layer_output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span> <span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">base_model</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">layer_output</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">lr_schedule</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">),</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_c</span><span class="p">,</span> <span class="n">y_train_c</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1">#Model Evaluation</span>
<span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test_c</span><span class="p">,</span> <span class="n">y_test_c</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>

<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;ResNet with Exponential LR&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">comparison_df2</span><span class="o">=</span><span class="n">comparison_df2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">row</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;configuration&#39;</span><span class="p">:</span> <span class="s1">&#39;ResNet with Exponential LR&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="o">*</span><span class="mi">100</span><span class="p">}</span>
<span class="n">final_comparison_df</span><span class="o">=</span><span class="n">final_comparison_df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
625/625 [==============================] - 27s 43ms/step - loss: 1.1016 - accuracy: 0.6312 - val_loss: 69.3114 - val_accuracy: 0.3311
Epoch 2/50
625/625 [==============================] - 26s 42ms/step - loss: 1.3747 - accuracy: 0.5095 - val_loss: 3.0207 - val_accuracy: 0.3452
Epoch 3/50
625/625 [==============================] - 26s 41ms/step - loss: 1.5706 - accuracy: 0.4404 - val_loss: 1.9257 - val_accuracy: 0.4789
Epoch 4/50
625/625 [==============================] - 26s 42ms/step - loss: 1.3850 - accuracy: 0.5170 - val_loss: 1.5061 - val_accuracy: 0.5041
Epoch 5/50
625/625 [==============================] - 26s 41ms/step - loss: 1.3539 - accuracy: 0.5304 - val_loss: 30.5717 - val_accuracy: 0.3751
Epoch 6/50
625/625 [==============================] - 26s 42ms/step - loss: 1.2242 - accuracy: 0.5787 - val_loss: 1.3070 - val_accuracy: 0.5775
Epoch 7/50
625/625 [==============================] - 26s 42ms/step - loss: 1.0257 - accuracy: 0.6484 - val_loss: 1.1007 - val_accuracy: 0.6241
Epoch 8/50
625/625 [==============================] - 26s 42ms/step - loss: 1.5861 - accuracy: 0.4339 - val_loss: 27.0859 - val_accuracy: 0.3490
Epoch 9/50
625/625 [==============================] - 26s 42ms/step - loss: 1.8399 - accuracy: 0.3311 - val_loss: 2.0457 - val_accuracy: 0.2611
Epoch 10/50
625/625 [==============================] - 26s 42ms/step - loss: 1.9764 - accuracy: 0.2783 - val_loss: 1.9552 - val_accuracy: 0.3612
Epoch 11/50
625/625 [==============================] - 26s 42ms/step - loss: 1.8464 - accuracy: 0.3321 - val_loss: 2.7239 - val_accuracy: 0.3714
Epoch 12/50
625/625 [==============================] - 26s 42ms/step - loss: 1.6657 - accuracy: 0.4016 - val_loss: 2.5633 - val_accuracy: 0.4230
Epoch 13/50
625/625 [==============================] - 26s 42ms/step - loss: 1.6158 - accuracy: 0.4178 - val_loss: 2.2829 - val_accuracy: 0.4548
Epoch 14/50
625/625 [==============================] - 26s 42ms/step - loss: 1.5416 - accuracy: 0.4455 - val_loss: 2.0691 - val_accuracy: 0.4649
Epoch 15/50
625/625 [==============================] - 26s 42ms/step - loss: 1.4768 - accuracy: 0.4743 - val_loss: 2.2805 - val_accuracy: 0.4827
Epoch 16/50
625/625 [==============================] - 26s 42ms/step - loss: 1.5157 - accuracy: 0.4592 - val_loss: 4748.5850 - val_accuracy: 0.0880
Epoch 17/50
625/625 [==============================] - 26s 42ms/step - loss: 1.6454 - accuracy: 0.4139 - val_loss: 2.4192 - val_accuracy: 0.4490
Epoch 18/50
625/625 [==============================] - 26s 42ms/step - loss: 1.7975 - accuracy: 0.3473 - val_loss: 2.5531 - val_accuracy: 0.2145
Epoch 19/50
625/625 [==============================] - 26s 42ms/step - loss: 1.8274 - accuracy: 0.3319 - val_loss: 45.0221 - val_accuracy: 0.3020
Epoch 20/50
625/625 [==============================] - 26s 42ms/step - loss: 1.6932 - accuracy: 0.3899 - val_loss: 2.3165 - val_accuracy: 0.4319
Epoch 21/50
625/625 [==============================] - 26s 41ms/step - loss: 1.5986 - accuracy: 0.4272 - val_loss: 3.7390 - val_accuracy: 0.4620
Epoch 22/50
625/625 [==============================] - 26s 41ms/step - loss: 1.7885 - accuracy: 0.3510 - val_loss: 204.6634 - val_accuracy: 0.1075
Epoch 23/50
625/625 [==============================] - 26s 42ms/step - loss: 2.0119 - accuracy: 0.2461 - val_loss: 15.2459 - val_accuracy: 0.3032
Epoch 24/50
625/625 [==============================] - 26s 41ms/step - loss: 2.2712 - accuracy: 0.1294 - val_loss: 2.3334 - val_accuracy: 0.1342
Epoch 25/50
625/625 [==============================] - 26s 41ms/step - loss: 2.2324 - accuracy: 0.1542 - val_loss: 2.5832 - val_accuracy: 0.1707
Epoch 26/50
625/625 [==============================] - 26s 41ms/step - loss: 2.1568 - accuracy: 0.1887 - val_loss: 2.0702 - val_accuracy: 0.2228
Epoch 27/50
625/625 [==============================] - 26s 41ms/step - loss: 2.0523 - accuracy: 0.2254 - val_loss: 1.9772 - val_accuracy: 0.2514
Epoch 28/50
625/625 [==============================] - 26s 41ms/step - loss: 1.9850 - accuracy: 0.2463 - val_loss: 2.0026 - val_accuracy: 0.2534
Epoch 29/50
625/625 [==============================] - 26s 41ms/step - loss: 1.9475 - accuracy: 0.2616 - val_loss: 1.9898 - val_accuracy: 0.2790
Epoch 30/50
625/625 [==============================] - 26s 42ms/step - loss: 1.9219 - accuracy: 0.2772 - val_loss: 2.1354 - val_accuracy: 0.2643
Epoch 31/50
625/625 [==============================] - 26s 41ms/step - loss: 1.8702 - accuracy: 0.2978 - val_loss: 1.9814 - val_accuracy: 0.3211
Epoch 32/50
625/625 [==============================] - 26s 42ms/step - loss: 1.8414 - accuracy: 0.3154 - val_loss: 3.2946 - val_accuracy: 0.2332
Epoch 33/50
625/625 [==============================] - 26s 41ms/step - loss: 1.8472 - accuracy: 0.3171 - val_loss: 2.0497 - val_accuracy: 0.3498
Epoch 34/50
625/625 [==============================] - 26s 41ms/step - loss: 1.8204 - accuracy: 0.3228 - val_loss: 1.8893 - val_accuracy: 0.3564
Epoch 35/50
625/625 [==============================] - 26s 41ms/step - loss: 1.7948 - accuracy: 0.3366 - val_loss: 2.2079 - val_accuracy: 0.3479
Epoch 36/50
625/625 [==============================] - 26s 41ms/step - loss: 1.7572 - accuracy: 0.3513 - val_loss: 1.9390 - val_accuracy: 0.3801
Epoch 37/50
625/625 [==============================] - 26s 42ms/step - loss: 1.7390 - accuracy: 0.3581 - val_loss: 2.1875 - val_accuracy: 0.2242
Epoch 38/50
625/625 [==============================] - 26s 41ms/step - loss: 1.8271 - accuracy: 0.3251 - val_loss: 252.8338 - val_accuracy: 0.1125
Epoch 39/50
625/625 [==============================] - 26s 41ms/step - loss: 1.9015 - accuracy: 0.3036 - val_loss: 2.8603 - val_accuracy: 0.3081
Epoch 40/50
625/625 [==============================] - 26s 41ms/step - loss: 1.8948 - accuracy: 0.3048 - val_loss: 2.0183 - val_accuracy: 0.3469
Epoch 41/50
625/625 [==============================] - 26s 41ms/step - loss: 1.8030 - accuracy: 0.3407 - val_loss: 1.8680 - val_accuracy: 0.3686
Epoch 42/50
625/625 [==============================] - 26s 41ms/step - loss: 1.7618 - accuracy: 0.3566 - val_loss: 1.7629 - val_accuracy: 0.3822
Epoch 43/50
625/625 [==============================] - 26s 42ms/step - loss: 1.7331 - accuracy: 0.3689 - val_loss: 1.6727 - val_accuracy: 0.3777
Epoch 44/50
625/625 [==============================] - 26s 42ms/step - loss: 1.7217 - accuracy: 0.3715 - val_loss: 2.3827 - val_accuracy: 0.3343
Epoch 45/50
625/625 [==============================] - 26s 41ms/step - loss: 1.7265 - accuracy: 0.3723 - val_loss: 1.7749 - val_accuracy: 0.3521
Epoch 46/50
625/625 [==============================] - 26s 41ms/step - loss: 1.7363 - accuracy: 0.3704 - val_loss: 1.9142 - val_accuracy: 0.3347
Epoch 47/50
625/625 [==============================] - 26s 41ms/step - loss: 1.7430 - accuracy: 0.3663 - val_loss: 1.7202 - val_accuracy: 0.3790
Epoch 48/50
625/625 [==============================] - 26s 42ms/step - loss: 1.7001 - accuracy: 0.3787 - val_loss: 49.0406 - val_accuracy: 0.3261
Epoch 49/50
625/625 [==============================] - 26s 42ms/step - loss: 1.7202 - accuracy: 0.3767 - val_loss: 1.7131 - val_accuracy: 0.4082
Epoch 50/50
625/625 [==============================] - 26s 41ms/step - loss: 1.7255 - accuracy: 0.3704 - val_loss: 2.0031 - val_accuracy: 0.3806
Accuracy: 38.420
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 2.3 Performance comparison<a rel="noopener" class="anchor-link" href="#Task-2.3-Performance-comparison">&#182;</a></h3><p><em>(weight ~5%)</em></p>
<p>Based on the above experiments, which method or which combination of methods result in the best accuracy with the same training time.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">comparison_df2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[19]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>configuration</th>
      <th>accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Shallow ConvNet</td>
      <td>70.980000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ResNet</td>
      <td>67.320001</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ResNet with Exponential LR</td>
      <td>92.369998</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">highest</span><span class="o">=</span><span class="n">comparison_df2</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The highest accuracy is observed for:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">comparison_df2</span><span class="p">[</span><span class="n">comparison_df2</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">highest</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>The highest accuracy is observed for:

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[20]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>configuration</th>
      <th>accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>ResNet with Exponential LR</td>
      <td>92.369998</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Task 3 Design a novel deep neural network model (Challenge Task for Targeting HD Grades)<a rel="noopener" class="anchor-link" href="#Task-3-Design-a-novel-deep-neural-network-model-(Challenge-Task-for-Targeting-HD-Grades)">&#182;</a></h2><p><em>(weight ~11%)</em>
Here, you have to show your critical idea to design a new neural network model. We will evaluate your results based on the novelty of the model and performance of the model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 3.1: The key idea to design a novel deep neural networks for CIFAR10<a rel="noopener" class="anchor-link" href="#Task-3.1:-The-key-idea-to-design-a-novel-deep-neural-networks-for-CIFAR10">&#182;</a></h3><p><em>(weight ~5%)</em></p>
<p>In this task, you will design a novel deep neural networks on the <a rel="noopener" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10 dataset</a>. CIFAR10 represents a relatively larger multi-class classification problem and presents a great opportunity for you to solve a &quot;harder&quot; problem. Different from Task 2, in this task you are required to design a novel neural network and optimize the performance in classification. In your answer, you have to clearly present what the key difference between your model and the classic ones, what the benefits in your design model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#AUTOENCODER-RNN</span>

<span class="c1">#!pip install tensorflow-gpu</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">UpSampling2D</span><span class="p">,</span> <span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">Activation</span>

<span class="p">(</span><span class="n">x_train_c</span><span class="p">,</span> <span class="n">y_train_c</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test_c</span><span class="p">,</span> <span class="n">y_test_c</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">y_train_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train_c</span><span class="p">)</span>
<span class="n">y_test_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test_c</span><span class="p">)</span>

<span class="n">x_train_re</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x_train_c</span><span class="p">)</span>
<span class="n">x_test_re</span>  <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x_test_c</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">CONVautoencoder</span><span class="p">(</span><span class="n">x_train_re</span><span class="p">,</span><span class="n">x_test_re</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="c1">## functional approach</span>
    <span class="c1">## input dimension is 3 so the output dimension will be 3</span>
    
    <span class="n">input_img</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">input_img</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">UpSampling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">UpSampling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">UpSampling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">decoded</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">autoencoder</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">input_img</span><span class="p">,</span><span class="n">decoded</span><span class="p">)</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">input_img</span><span class="p">,</span><span class="n">encoded</span><span class="p">)</span>
    <span class="n">autoencoder</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="c1">## we dont need to compile the encoder model</span>
    <span class="c1">## it is the sub model of the auto encoder</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
    <span class="n">autoencoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_re</span><span class="p">,</span><span class="n">x_train_re</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span><span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test_re</span><span class="p">,</span><span class="n">x_test_re</span><span class="p">))</span>
    
    <span class="n">encoded_imgs</span><span class="o">=</span><span class="n">encoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_re</span><span class="p">)</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_re</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">encoded_imgs</span><span class="p">,</span><span class="n">predicted</span>

    <span class="k">return</span> <span class="n">encoded_imgs</span><span class="p">,</span><span class="n">predicted</span>

<span class="n">encoded_imgs</span><span class="p">,</span><span class="n">predicted</span> <span class="o">=</span> <span class="n">CONVautoencoder</span><span class="p">(</span><span class="n">x_train_re</span><span class="p">,</span><span class="n">x_test_re</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &quot;functional_9&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 32, 32, 64)        1792      
_________________________________________________________________
batch_normalization (BatchNo (None, 32, 32, 64)        256       
_________________________________________________________________
activation (Activation)      (None, 32, 32, 64)        0         
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 16, 16, 32)        18464     
_________________________________________________________________
batch_normalization_1 (Batch (None, 16, 16, 32)        128       
_________________________________________________________________
activation_1 (Activation)    (None, 16, 16, 32)        0         
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 8, 8, 16)          4624      
_________________________________________________________________
batch_normalization_2 (Batch (None, 8, 8, 16)          64        
_________________________________________________________________
activation_2 (Activation)    (None, 8, 8, 16)          0         
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 4, 4, 16)          0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 4, 4, 16)          2320      
_________________________________________________________________
batch_normalization_3 (Batch (None, 4, 4, 16)          64        
_________________________________________________________________
activation_3 (Activation)    (None, 4, 4, 16)          0         
_________________________________________________________________
up_sampling2d (UpSampling2D) (None, 8, 8, 16)          0         
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 8, 8, 32)          4640      
_________________________________________________________________
batch_normalization_4 (Batch (None, 8, 8, 32)          128       
_________________________________________________________________
activation_4 (Activation)    (None, 8, 8, 32)          0         
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 16, 16, 64)        18496     
_________________________________________________________________
batch_normalization_5 (Batch (None, 16, 16, 64)        256       
_________________________________________________________________
activation_5 (Activation)    (None, 16, 16, 64)        0         
_________________________________________________________________
up_sampling2d_2 (UpSampling2 (None, 32, 32, 64)        0         
_________________________________________________________________
conv2d_16 (Conv2D)           (None, 32, 32, 3)         1731      
_________________________________________________________________
batch_normalization_6 (Batch (None, 32, 32, 3)         12        
_________________________________________________________________
activation_6 (Activation)    (None, 32, 32, 3)         0         
=================================================================
Total params: 52,975
Trainable params: 52,521
Non-trainable params: 454
_________________________________________________________________
None
Model: &quot;functional_11&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 32, 32, 64)        1792      
_________________________________________________________________
batch_normalization (BatchNo (None, 32, 32, 64)        256       
_________________________________________________________________
activation (Activation)      (None, 32, 32, 64)        0         
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 16, 16, 32)        18464     
_________________________________________________________________
batch_normalization_1 (Batch (None, 16, 16, 32)        128       
_________________________________________________________________
activation_1 (Activation)    (None, 16, 16, 32)        0         
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 8, 8, 16)          4624      
_________________________________________________________________
batch_normalization_2 (Batch (None, 8, 8, 16)          64        
_________________________________________________________________
activation_2 (Activation)    (None, 8, 8, 16)          0         
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 4, 4, 16)          0         
=================================================================
Total params: 25,328
Trainable params: 25,104
Non-trainable params: 224
_________________________________________________________________
None
Epoch 1/50
782/782 [==============================] - 7s 9ms/step - loss: 0.6740 - accuracy: 0.6973 - val_loss: 0.6638 - val_accuracy: 0.7772
Epoch 2/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6623 - accuracy: 0.7702 - val_loss: 0.6615 - val_accuracy: 0.7879
Epoch 3/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6612 - accuracy: 0.7860 - val_loss: 0.6609 - val_accuracy: 0.8052
Epoch 4/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6607 - accuracy: 0.7928 - val_loss: 0.6603 - val_accuracy: 0.8165
Epoch 5/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6603 - accuracy: 0.7978 - val_loss: 0.6601 - val_accuracy: 0.7979
Epoch 6/50
782/782 [==============================] - 7s 9ms/step - loss: 0.6601 - accuracy: 0.8020 - val_loss: 0.6600 - val_accuracy: 0.8102
Epoch 7/50
782/782 [==============================] - 7s 9ms/step - loss: 0.6599 - accuracy: 0.8038 - val_loss: 0.6598 - val_accuracy: 0.8167
Epoch 8/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6597 - accuracy: 0.8071 - val_loss: 0.6596 - val_accuracy: 0.8248
Epoch 9/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6596 - accuracy: 0.8083 - val_loss: 0.6595 - val_accuracy: 0.8067
Epoch 10/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6595 - accuracy: 0.8091 - val_loss: 0.6598 - val_accuracy: 0.8093
Epoch 11/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6594 - accuracy: 0.8095 - val_loss: 0.6593 - val_accuracy: 0.8355
Epoch 12/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6593 - accuracy: 0.8114 - val_loss: 0.6596 - val_accuracy: 0.8095
Epoch 13/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6592 - accuracy: 0.8118 - val_loss: 0.6591 - val_accuracy: 0.8212
Epoch 14/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6592 - accuracy: 0.8123 - val_loss: 0.6594 - val_accuracy: 0.8038
Epoch 15/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6592 - accuracy: 0.8133 - val_loss: 0.6592 - val_accuracy: 0.7827
Epoch 16/50
782/782 [==============================] - 7s 9ms/step - loss: 0.6591 - accuracy: 0.8141 - val_loss: 0.6589 - val_accuracy: 0.8299
Epoch 17/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6591 - accuracy: 0.8139 - val_loss: 0.6591 - val_accuracy: 0.7998
Epoch 18/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6590 - accuracy: 0.8148 - val_loss: 0.6589 - val_accuracy: 0.8135
Epoch 19/50
782/782 [==============================] - 7s 9ms/step - loss: 0.6590 - accuracy: 0.8139 - val_loss: 0.6604 - val_accuracy: 0.7712
Epoch 20/50
782/782 [==============================] - 7s 9ms/step - loss: 0.6589 - accuracy: 0.8150 - val_loss: 0.6591 - val_accuracy: 0.8358
Epoch 21/50
782/782 [==============================] - 7s 9ms/step - loss: 0.6589 - accuracy: 0.8163 - val_loss: 0.6594 - val_accuracy: 0.7450
Epoch 22/50
782/782 [==============================] - 7s 9ms/step - loss: 0.6589 - accuracy: 0.8150 - val_loss: 0.6591 - val_accuracy: 0.8259
Epoch 23/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6588 - accuracy: 0.8167 - val_loss: 0.6588 - val_accuracy: 0.8209
Epoch 24/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6589 - accuracy: 0.8149 - val_loss: 0.6587 - val_accuracy: 0.8121
Epoch 25/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6588 - accuracy: 0.8174 - val_loss: 0.6586 - val_accuracy: 0.8430
Epoch 26/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6588 - accuracy: 0.8178 - val_loss: 0.6588 - val_accuracy: 0.8070
Epoch 27/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6588 - accuracy: 0.8168 - val_loss: 0.6589 - val_accuracy: 0.8114
Epoch 28/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6588 - accuracy: 0.8195 - val_loss: 0.6586 - val_accuracy: 0.8314
Epoch 29/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6588 - accuracy: 0.8175 - val_loss: 0.6587 - val_accuracy: 0.8127
Epoch 30/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6588 - accuracy: 0.8183 - val_loss: 0.6587 - val_accuracy: 0.8442
Epoch 31/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6587 - accuracy: 0.8177 - val_loss: 0.6586 - val_accuracy: 0.8156
Epoch 32/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6587 - accuracy: 0.8182 - val_loss: 0.6588 - val_accuracy: 0.8347
Epoch 33/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6587 - accuracy: 0.8185 - val_loss: 0.6587 - val_accuracy: 0.8492
Epoch 34/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6587 - accuracy: 0.8177 - val_loss: 0.6589 - val_accuracy: 0.7917
Epoch 35/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6587 - accuracy: 0.8173 - val_loss: 0.6589 - val_accuracy: 0.8268
Epoch 36/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6587 - accuracy: 0.8184 - val_loss: 0.6591 - val_accuracy: 0.7937
Epoch 37/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6587 - accuracy: 0.8188 - val_loss: 0.6585 - val_accuracy: 0.8465
Epoch 38/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6587 - accuracy: 0.8189 - val_loss: 0.6585 - val_accuracy: 0.8237
Epoch 39/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6586 - accuracy: 0.8206 - val_loss: 0.6587 - val_accuracy: 0.8044
Epoch 40/50
782/782 [==============================] - 7s 9ms/step - loss: 0.6587 - accuracy: 0.8188 - val_loss: 0.6586 - val_accuracy: 0.8296
Epoch 41/50
782/782 [==============================] - 7s 9ms/step - loss: 0.6586 - accuracy: 0.8187 - val_loss: 0.6586 - val_accuracy: 0.8151
Epoch 42/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6586 - accuracy: 0.8206 - val_loss: 0.6586 - val_accuracy: 0.8254
Epoch 43/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6586 - accuracy: 0.8176 - val_loss: 0.6586 - val_accuracy: 0.8460
Epoch 44/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6586 - accuracy: 0.8190 - val_loss: 0.6585 - val_accuracy: 0.8392
Epoch 45/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6586 - accuracy: 0.8180 - val_loss: 0.6585 - val_accuracy: 0.8345
Epoch 46/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6586 - accuracy: 0.8199 - val_loss: 0.6586 - val_accuracy: 0.8349
Epoch 47/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6586 - accuracy: 0.8197 - val_loss: 0.6584 - val_accuracy: 0.8311
Epoch 48/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6586 - accuracy: 0.8214 - val_loss: 0.6585 - val_accuracy: 0.8343
Epoch 49/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6586 - accuracy: 0.8194 - val_loss: 0.6586 - val_accuracy: 0.8351
Epoch 50/50
782/782 [==============================] - 7s 8ms/step - loss: 0.6586 - accuracy: 0.8200 - val_loss: 0.6586 - val_accuracy: 0.8239
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The key difference between the autoencoder and classic model is that in rnn model output from the previous step is fed as input to the current step&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>The key difference between the autoencoder and classic model is that in rnn model output from the previous step is fed as input to the current step
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 3.2: The implementation of the novel deep neural networks for CIFAR10<a rel="noopener" class="anchor-link" href="#Task-3.2:-The-implementation-of-the-novel-deep-neural-networks-for-CIFAR10">&#182;</a></h3><p><em>(weight ~6%)</em></p>
<p>In this task, it requires you to write the codes for model implementation and report the performance. In your results, you have to demonstrate the compared performance of your new model and the state-of-the-art models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">final_comparison_df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[23]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>configuration</th>
      <th>accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ConvNet</td>
      <td>88.929999</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ImageDataGenerator</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Transfer Learning with Fine Tuning</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Transfer Learning without Fine Tuning</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Shallow ConvNet</td>
      <td>70.980000</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ResNet</td>
      <td>67.320001</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ResNet with Exponential LR</td>
      <td>38.420001</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong>END OF ASSIGNMENT TWO</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Html Output Code</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="k">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">,</span> <span class="n">force_remount</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Mounted at /content/drive
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install nbconvert
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (5.6.1)
Requirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.8.4)
Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.6.1)
Requirement already satisfied: nbformat&gt;=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (5.0.7)
Requirement already satisfied: pandocfilters&gt;=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (1.4.2)
Requirement already satisfied: jinja2&gt;=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.11.2)
Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.4.4)
Requirement already satisfied: traitlets&gt;=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.3.3)
Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.6.0)
Requirement already satisfied: entrypoints&gt;=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.3)
Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert) (3.2.1)
Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.6.3)
Requirement already satisfied: jsonschema!=2.5.0,&gt;=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat&gt;=4.4-&gt;nbconvert) (2.6.0)
Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat&gt;=4.4-&gt;nbconvert) (0.2.0)
Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2&gt;=2.4-&gt;nbconvert) (1.1.1)
Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets&gt;=4.2-&gt;nbconvert) (4.4.2)
Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets&gt;=4.2-&gt;nbconvert) (1.15.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach-&gt;nbconvert) (20.4)
Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach-&gt;nbconvert) (0.5.1)
Requirement already satisfied: pyparsing&gt;=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging-&gt;bleach-&gt;nbconvert) (2.4.7)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>jupyter nbconvert --to html Copy of 218612723_Assignment_2_solution.ipynb
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[NbConvertApp] WARNING | pattern u&#39;Copy&#39; matched no files
[NbConvertApp] WARNING | pattern u&#39;of&#39; matched no files
[NbConvertApp] WARNING | pattern u&#39;218612723_Assignment_2_solution.ipynb&#39; matched no files
This application is used to convert notebook files (*.ipynb) to various other
formats.

WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.

Options
-------

Arguments that take values are actually convenience aliases to full
Configurables, whose aliases are listed on the help line. For more information
on full configurables, see &#39;--help-all&#39;.

--execute
    Execute the notebook prior to export.
--allow-errors
    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if &#39;--execute&#39; was specified, too.
--no-input
    Exclude input cells and output prompts from converted document. 
    This mode is ideal for generating code-free reports.
--stdout
    Write notebook output to stdout instead of files.
--stdin
    read a single notebook file from stdin. Write the resulting notebook with default basename &#39;notebook.*&#39;
--inplace
    Run nbconvert in place, overwriting the existing notebook (only 
    relevant when converting to notebook format)
-y
    Answer yes to any questions instead of prompting.
--clear-output
    Clear output of current file and save in place, 
    overwriting the existing notebook.
--debug
    set log level to logging.DEBUG (maximize logging output)
--no-prompt
    Exclude input and output prompts from converted document.
--generate-config
    generate default config file
--nbformat=&lt;Enum&gt; (NotebookExporter.nbformat_version)
    Default: 4
    Choices: [1, 2, 3, 4]
    The nbformat version to write. Use this to downgrade notebooks.
--output-dir=&lt;Unicode&gt; (FilesWriter.build_directory)
    Default: &#39;&#39;
    Directory to write output(s) to. Defaults to output to the directory of each
    notebook. To recover previous default behaviour (outputting to the current
    working directory) use . as the flag value.
--writer=&lt;DottedObjectName&gt; (NbConvertApp.writer_class)
    Default: &#39;FilesWriter&#39;
    Writer class used to write the  results of the conversion
--log-level=&lt;Enum&gt; (Application.log_level)
    Default: 30
    Choices: (0, 10, 20, 30, 40, 50, &#39;DEBUG&#39;, &#39;INFO&#39;, &#39;WARN&#39;, &#39;ERROR&#39;, &#39;CRITICAL&#39;)
    Set the log level by value or name.
--reveal-prefix=&lt;Unicode&gt; (SlidesExporter.reveal_url_prefix)
    Default: u&#39;&#39;
    The URL prefix for reveal.js (version 3.x). This defaults to the reveal CDN,
    but can be any url pointing to a copy  of reveal.js.
    For speaker notes to work, this must be a relative path to a local  copy of
    reveal.js: e.g., &quot;reveal.js&quot;.
    If a relative path is given, it must be a subdirectory of the current
    directory (from which the server is run).
    See the usage documentation
    (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-
    slideshow) for more details.
--to=&lt;Unicode&gt; (NbConvertApp.export_format)
    Default: &#39;html&#39;
    The export format to be used, either one of the built-in formats
    [&#39;asciidoc&#39;, &#39;custom&#39;, &#39;html&#39;, &#39;latex&#39;, &#39;markdown&#39;, &#39;notebook&#39;, &#39;pdf&#39;,
    &#39;python&#39;, &#39;rst&#39;, &#39;script&#39;, &#39;slides&#39;] or a dotted object name that represents
    the import path for an `Exporter` class
--template=&lt;Unicode&gt; (TemplateExporter.template_file)
    Default: u&#39;&#39;
    Name of the template file to use
--output=&lt;Unicode&gt; (NbConvertApp.output_base)
    Default: &#39;&#39;
    overwrite base name use for output files. can only be used when converting
    one notebook at a time.
--post=&lt;DottedOrNone&gt; (NbConvertApp.postprocessor_class)
    Default: u&#39;&#39;
    PostProcessor class used to write the results of the conversion
--config=&lt;Unicode&gt; (JupyterApp.config_file)
    Default: u&#39;&#39;
    Full path of a config file.

To see all available configurables, use `--help-all`

Examples
--------

    The simplest way to use nbconvert is
    
    &gt; jupyter nbconvert mynotebook.ipynb
    
    which will convert mynotebook.ipynb to the default format (probably HTML).
    
    You can specify the export format with `--to`.
    Options include [&#39;asciidoc&#39;, &#39;custom&#39;, &#39;html&#39;, &#39;latex&#39;, &#39;markdown&#39;, &#39;notebook&#39;, &#39;pdf&#39;, &#39;python&#39;, &#39;rst&#39;, &#39;script&#39;, &#39;slides&#39;].
    
    &gt; jupyter nbconvert --to latex mynotebook.ipynb
    
    Both HTML and LaTeX support multiple output templates. LaTeX includes
    &#39;base&#39;, &#39;article&#39; and &#39;report&#39;.  HTML includes &#39;basic&#39; and &#39;full&#39;. You
    can specify the flavor of the format used.
    
    &gt; jupyter nbconvert --to html --template basic mynotebook.ipynb
    
    You can also pipe the output to stdout, rather than a file
    
    &gt; jupyter nbconvert mynotebook.ipynb --stdout
    
    PDF is generated via latex
    
    &gt; jupyter nbconvert mynotebook.ipynb --to pdf
    
    You can get (and serve) a Reveal.js-powered slideshow
    
    &gt; jupyter nbconvert myslides.ipynb --to slides --post serve
    
    Multiple notebooks can be given at the command line in a couple of 
    different ways:
    
    &gt; jupyter nbconvert notebook*.ipynb
    &gt; jupyter nbconvert notebook1.ipynb notebook2.ipynb
    
    or you can specify the notebooks list in a config file, containing::
    
        c.NbConvertApp.notebooks = [&quot;my_notebook.ipynb&quot;]
    
    &gt; jupyter nbconvert --config mycfg.py

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="k">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Mounted at /content/drive
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    </div>
  </div>


 



<script type="text/javascript" src="/d2l/common/math/MathML.js?v=20.21.8.31625 "></script><script type="text/javascript">document.addEventListener('DOMContentLoaded', function() { D2LMathML.DesktopInit('https://s.brightspace.com/lib/mathjax/2.7.4/MathJax.js?config=MML_HTMLorMML','https://s.brightspace.com/lib/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML','130',true); });</script></body></html>